{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMj0TdaGaNYP/BXzd9RSxdZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oyekanmi/Machine-Learning-New/blob/master/Income%20Predictions%20with%20ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd_035NYQRIB",
        "colab_type": "text"
      },
      "source": [
        "**Census Income**\n",
        "\n",
        "Predict if an individual makes greater or less than $50000 per year\n",
        "\n",
        "\n",
        "**Attribute Details**:\n",
        "\n",
        "**Name**\tType\tDescription\n",
        "\n",
        "**age**\tinteger\tage of individual\n",
        "\n",
        "**workclass**\tstring\tValues: \n",
        "\n",
        "**fnlwgt**\tfloat\tFinal sampling weight. \n",
        "\n",
        "**education**\tstring\tValues: \n",
        "\n",
        "**education_num**\tinteger\t\n",
        "\n",
        "**marital_status**\tstring\tValues:\n",
        "\n",
        "**occupation**\tstring\tValues: \n",
        "\n",
        "**relationship**\tstring\tValues: \n",
        "\n",
        "**race**\tstring\tValues: \n",
        "\n",
        "**sex**\tstring\tValues: Female, Male\n",
        "\n",
        "**capital_gain**\tfloat\t\n",
        "\n",
        "**capital_loss**\tfloat\t\n",
        "\n",
        "**hours_per_week**\tfloat\tworking hours per week\n",
        "\n",
        "**native_country**\tstring\tValues: \n",
        "\n",
        "**income_level**\tstring\tPredictor class if individual earns greater or less than $50000 per year. Values: <=50K, >50K\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzmhWM1AQSmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#import machine learning libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#Hyperparameter Tuning\n",
        "\n",
        "#import Deep Learning Libraries\n",
        "import tensorflow as tf\n",
        "\n",
        "#import evaluation metrics\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score, roc_curve"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7PjQlPJQehX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f722cbef-76ca-45c7-deb9-05d8e8c3ec94"
      },
      "source": [
        "census_income = pd.read_csv('census_income_dataset.csv')  #load dataframe\n",
        "\n",
        "census_income.head() #view the first five rows"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516.0</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311.0</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646.0</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721.0</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409.0</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         workclass    fnlwgt  ... hours_per_week  native_country income_level\n",
              "0   39         State-gov   77516.0  ...           40.0   United-States        <=50K\n",
              "1   50  Self-emp-not-inc   83311.0  ...           13.0   United-States        <=50K\n",
              "2   38           Private  215646.0  ...           40.0   United-States        <=50K\n",
              "3   53           Private  234721.0  ...           40.0   United-States        <=50K\n",
              "4   28           Private  338409.0  ...           40.0            Cuba        <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKjdPeYnQmA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9ae9d008-d64b-466f-a645-92711ac95432"
      },
      "source": [
        "# replace the income level with a value of 1 or 0 : 1 for income > 50k and 0 for income <= 50k\n",
        "\n",
        "census_income['income_level'] = census_income.loc[:,'income_level'].apply (lambda x: 0 if x == '<=50K' else 1)\n",
        "\n",
        "census_income.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516.0</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311.0</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646.0</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721.0</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409.0</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         workclass    fnlwgt  ... hours_per_week  native_country income_level\n",
              "0   39         State-gov   77516.0  ...           40.0   United-States            0\n",
              "1   50  Self-emp-not-inc   83311.0  ...           13.0   United-States            0\n",
              "2   38           Private  215646.0  ...           40.0   United-States            0\n",
              "3   53           Private  234721.0  ...           40.0   United-States            0\n",
              "4   28           Private  338409.0  ...           40.0            Cuba            0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ruxrf5FgQmjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "025079c7-7c3b-4c07-86f3-06291d4d4a47"
      },
      "source": [
        "census_income.shape   #check the size of the dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48842, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L33eastQw6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3bc79f64-0f1e-4153-b8bb-9cf6a5503492"
      },
      "source": [
        "census_income.loc[:,'income_level'].value_counts()     #check for the size of each class present "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    37155\n",
              "1    11687\n",
              "Name: income_level, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuBAdNixQ2Kp",
        "colab_type": "text"
      },
      "source": [
        "The result shows that we have uneven classes present . 37155 people with income <=50K and 11687 people with income > 50k."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KILIc7OHQ73m",
        "colab_type": "text"
      },
      "source": [
        "**Data Preparation and EDA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqIDfkMlQxd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5eda658a-4c37-425d-a62a-261d1c84f42c"
      },
      "source": [
        "country_counts = census_income.loc[:,'native_country'].value_counts(normalize=True)    #count the number of unique values in the country column\n",
        "\n",
        "country_by_percent = country_counts * 100          # conver to percentage\n",
        "\n",
        "print(country_by_percent.head(10))    #view the first five rows\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "United-States    89.742435\n",
            "Mexico            1.947095\n",
            "?                 1.754637\n",
            "Philippines       0.603988\n",
            "Germany           0.421768\n",
            "Puerto-Rico       0.376725\n",
            "Canada            0.372630\n",
            "El-Salvador       0.317350\n",
            "India             0.309160\n",
            "Cuba              0.282544\n",
            "Name: native_country, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsTyMf8aRFSq",
        "colab_type": "text"
      },
      "source": [
        "Result above shows that about 90% of the dataset is from the United States . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLNnIG1lQ_7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a85cf883-a256-48f5-b330-37b357674bad"
      },
      "source": [
        "census_income.isna().sum()   #check for missing value"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age               0\n",
              "workclass         0\n",
              "fnlwgt            0\n",
              "education         0\n",
              "education_num     0\n",
              "marital_status    0\n",
              "occupation        0\n",
              "relationship      0\n",
              "race              0\n",
              "sex               0\n",
              "capital_gain      0\n",
              "capital_loss      0\n",
              "hours_per_week    0\n",
              "native_country    0\n",
              "income_level      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMHEVX8CRKmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac448a84-8382-41df-f42b-f700ebb3818b"
      },
      "source": [
        "#exclude rows whose native_country is unknown or 'Holand-Netherlands'\n",
        "census_income = census_income[(census_income['native_country'] != '?') ]    # exclude rows whose native is ?\n",
        "\n",
        "print(f\" The new dataframe has {census_income.shape[0]} rows and {census_income.shape[1]} columns\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " The new dataframe has 47985 rows and 15 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISyM7sbsRN5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "9f7f8da1-2a35-4c30-9405-ea775a8cd84c"
      },
      "source": [
        "#check the age distribution\n",
        "census_income['age'].hist(bins=20, figsize= (12,6))\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Counts')\n",
        "plt.title('Distribution of Age')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Distribution of Age')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPhq2wIlRcqI",
        "colab_type": "text"
      },
      "source": [
        "The result shows that the dataset is skewed to the right.The ages of most people falls between 20 and 65 years"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEjAcnA_RYH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "e57d15eb-2cc1-4818-ccfb-6957ec66d85b"
      },
      "source": [
        "census_income['education'].value_counts().sort_values().plot(kind='barh', figsize = (10,8), title=' Income by Education')   # check for the highest education of the people \n",
        "plt.tick_params(axis='both', labelsize=12)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU917DB9RgQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "5cad27fb-7955-4df5-fce5-92771edc1c80"
      },
      "source": [
        "census_income.loc[:,'race'].value_counts(normalize=True).sort_values().plot(kind='barh', figsize = (12,6), title=' Age distribution used ')    # Check the age distribution of the data \n",
        "\n",
        "plt.xlabel('Count', fontsize=14)  #set x label\n",
        "plt.ylabel('race', fontsize = 14)   #set y label\n",
        "plt.tick_params(axis='both', labelsize=12)  #increase the axis font size"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTiL76BURnDx",
        "colab_type": "text"
      },
      "source": [
        "Over 80% of the demographics of the data collected consist of white people"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy9y7n9IRjno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Since 'relationship' and 'education' columns are redundants , we can drop them\n",
        "\n",
        "census_income.drop(labels= ['relationship', 'education'], axis= 'columns' , inplace=True )  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AypAt_3HRqsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6566dc91-bdcc-4be7-8df5-16360510ae4f"
      },
      "source": [
        "print(f\" The new dataframe has {census_income.shape[0]} rows and {census_income.shape[1]} columns\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " The new dataframe has 47985 rows and 13 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaegCXk3RtJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count the number of '?' in the dataframe\n",
        "count= 0\n",
        "\n",
        "for i in range(47985):\n",
        "  for j in range(12):\n",
        "    if census_income.iloc[i,j]== '?':\n",
        "      count+=1\n",
        "    else:\n",
        "      pass"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoIfZ6liRvNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f50b773-5635-44fa-ab3e-3443cee728e1"
      },
      "source": [
        "print( f\"There are {count} '?' present in the data\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 5516 '?' present in the data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrs44KCXRxOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get the row indices that countains '?\n",
        "index_with_mark = []         #initiate an empty list\n",
        "count = 0\n",
        "for i in range(47985):   #iterate over all rows\n",
        "  for j in range(12):    #iterate over all columns\n",
        "    if census_income.iloc[i,j]== '?':      #check for '?'\n",
        "      index_with_mark.append(i)\n",
        "      count+=1\n",
        "    else:\n",
        "      pass"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXgZYOmuRz3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88b6d3c7-60aa-474a-8fb3-566c524ef302"
      },
      "source": [
        "print(f\"There are {len(set(index_with_mark))} unique indices that contains '?' \")  #count the number of unique rows with '?' present in the dataframe\n",
        "\n",
        "unique_indices = list(set(index_with_mark))  #get the number of unique indices"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 2763 unique indices that contains '?' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_J1FfnnR24B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "census_income.drop(census_income.index[unique_indices], inplace=True)      #drop the rows which contains ?"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKzMvev2R4_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09e454f6-1456-4093-91c7-f6f72ff94ac8"
      },
      "source": [
        "census_income.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45222, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUV0VWCIR6zY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cacbdbf2-4799-472d-cca4-9e3e0522dea7"
      },
      "source": [
        "#Verify that no columns contains '?\n",
        "index_with_mark = []         #initiate an empty list\n",
        "count = 0\n",
        "for i in range(len(census_income)-1):   #iterate over all rows\n",
        "  for j in range(12):    #iterate over all columns\n",
        "    if census_income.iloc[i,j]== '?':      #check for '?'\n",
        "      index_with_mark.append(i)\n",
        "      count+=1\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "len(index_with_mark)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppGRkah3R96T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "c4bbcd94-f407-4130-f9c8-7dacbd3db301"
      },
      "source": [
        "pd.crosstab(census_income.sex, census_income.race )   "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>race</th>\n",
              "      <th>Amer-Indian-Eskimo</th>\n",
              "      <th>Asian-Pac-Islander</th>\n",
              "      <th>Black</th>\n",
              "      <th>Other</th>\n",
              "      <th>White</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Female</th>\n",
              "      <td>166</td>\n",
              "      <td>436</td>\n",
              "      <td>2084</td>\n",
              "      <td>126</td>\n",
              "      <td>11883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Male</th>\n",
              "      <td>269</td>\n",
              "      <td>867</td>\n",
              "      <td>2144</td>\n",
              "      <td>227</td>\n",
              "      <td>27020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "race    Amer-Indian-Eskimo  Asian-Pac-Islander  Black  Other  White\n",
              "sex                                                                \n",
              "Female                 166                 436   2084    126  11883\n",
              "Male                   269                 867   2144    227  27020"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6RE-PUJSAF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "25631a09-853e-4a72-81d9-0704b64c2696"
      },
      "source": [
        "# View the first five rows of the dataset\n",
        "\n",
        "census_income.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516.0</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311.0</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646.0</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721.0</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409.0</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         workclass    fnlwgt  ...  hours_per_week native_country income_level\n",
              "0   39         State-gov   77516.0  ...            40.0  United-States            0\n",
              "1   50  Self-emp-not-inc   83311.0  ...            13.0  United-States            0\n",
              "2   38           Private  215646.0  ...            40.0  United-States            0\n",
              "3   53           Private  234721.0  ...            40.0  United-States            0\n",
              "4   28           Private  338409.0  ...            40.0           Cuba            0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOJetHMeSDYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "bb06928a-ed34-4520-809c-38ce09ac6e74"
      },
      "source": [
        "census_income.workclass.value_counts()  #check the distribution of values for the workclass column"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Private             33307\n",
              "Self-emp-not-inc     3796\n",
              "Local-gov            3100\n",
              "State-gov            1946\n",
              "Self-emp-inc         1646\n",
              "Federal-gov          1406\n",
              "Without-pay            21\n",
              "Name: workclass, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj1ABiS1SSe1",
        "colab_type": "text"
      },
      "source": [
        "**Split Dataset into Training , Validation and Test Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl8MMFtESWfI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Define a function that Splits into Training , Validation and Test Sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeSqKYihSH5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_stratified_into_train_val_test(df_input, stratify_colname='y',\n",
        "                                         frac_train=0.7, frac_val=0.15, frac_test=0.15,\n",
        "                                         random_state=None):\n",
        "    '''\n",
        "    Splits a Pandas dataframe into three subsets (train, val, and test)\n",
        "    following fractional ratios provided by the user, where each subset is\n",
        "    stratified by the values in a specific column (that is, each subset has\n",
        "    the same relative frequency of the values in the column). It performs this\n",
        "    splitting by running train_test_split() twice.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df_input : Pandas dataframe\n",
        "        Input dataframe to be split.\n",
        "    stratify_colname : str\n",
        "        The name of the column that will be used for stratification. Usually\n",
        "        this column would be for the label.\n",
        "    frac_train : float\n",
        "    frac_val   : float\n",
        "    frac_test  : float\n",
        "        The ratios with which the dataframe will be split into train, val, and\n",
        "        test data. The values should be expressed as float fractions and should\n",
        "        sum to 1.0.\n",
        "    random_state : int, None, or RandomStateInstance\n",
        "        Value to be passed to train_test_split().\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    df_train, df_val, df_test :\n",
        "        Dataframes containing the three splits.\n",
        "    '''\n",
        "\n",
        "    if frac_train + frac_val + frac_test != 1.0:\n",
        "        raise ValueError('fractions %f, %f, %f do not add up to 1.0' % \\\n",
        "                         (frac_train, frac_val, frac_test))\n",
        "\n",
        "    if stratify_colname not in df_input.columns:\n",
        "        raise ValueError('%s is not a column in the dataframe' % (stratify_colname))\n",
        "\n",
        "    X = df_input # Contains all columns.\n",
        "    y = df_input[[stratify_colname]] # Dataframe of just the column on which to stratify.\n",
        "\n",
        "    # Split original dataframe into train and temp dataframes.\n",
        "    df_train, df_temp, y_train, y_temp = train_test_split(X,\n",
        "                                                          y,\n",
        "                                                          stratify=y,\n",
        "                                                          test_size=(1.0 - frac_train),\n",
        "                                                          random_state=random_state)\n",
        "\n",
        "    # Split the temp dataframe into val and test dataframes.\n",
        "    relative_frac_test = frac_test / (frac_val + frac_test)\n",
        "    df_val, df_test, y_val, y_test = train_test_split(df_temp,\n",
        "                                                      y_temp,\n",
        "                                                      stratify=y_temp,\n",
        "                                                      test_size=relative_frac_test,\n",
        "                                                      random_state=random_state)\n",
        "\n",
        "    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n",
        "    return df_train, df_val, df_test"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqm9Z6RWSb9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ee13d6d6-ff22-418f-ec4f-565ed30b3a49"
      },
      "source": [
        "# Split the dataframe into train, val and test set\n",
        "df_train,df_val,df_test = split_stratified_into_train_val_test(census_income, stratify_colname='income_level',\n",
        "                                         frac_train=0.7, frac_val=0.15, frac_test=0.15,\n",
        "                                         random_state=42)\n",
        "\n",
        "# print the shapes of training , validation and test data\n",
        "print(f\"Shape of training data {df_train.shape}\")\n",
        "print(f\"Shape of validation data {df_val.shape}\")\n",
        "print(f\"Shape of test data {df_test.shape}\")\n",
        "\n",
        "\n",
        "# Create the training variables \n",
        "X_train = df_train.loc[:, :'native_country' ]\n",
        "y_train = df_train.loc[:, 'income_level' ]\n",
        "\n",
        "# Create the validation variables \n",
        "X_val = df_val.loc[:, :'native_country' ]\n",
        "y_val = df_val.loc[:, 'income_level' ]\n",
        "\n",
        "#create the test variables\n",
        "X_test = df_test.loc[:, :'native_country' ]\n",
        "y_test = df_test.loc[:, 'income_level' ]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data (31655, 13)\n",
            "Shape of validation data (6783, 13)\n",
            "Shape of test data (6784, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIFCG3uDSjuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "437bc298-0a9f-4021-a7bb-ea74176cd333"
      },
      "source": [
        "y_train.value_counts()  #check the class proportion"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    23809\n",
              "1     7846\n",
              "Name: income_level, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud4Zb1DFSu48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "81ba15c3-addb-4aee-eae2-c4bffd27f808"
      },
      "source": [
        "# create a list of the numerical col and categorical columns\n",
        "categorical_col = [col for col in X_train.columns if X_train[col].dtypes == 'object']\n",
        "print(categorical_col)\n",
        "\n",
        "numerical_col = list (set(X_train.columns) - set(categorical_col))\n",
        "print('\\n')\n",
        "\n",
        "print(numerical_col)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['workclass', 'marital_status', 'occupation', 'race', 'sex', 'native_country']\n",
            "\n",
            "\n",
            "['age', 'fnlwgt', 'capital_gain', 'education_num', 'capital_loss', 'hours_per_week']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e6rjsEFTJXL",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing for Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQVVUuAx4RND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ohe = OneHotEncoder(sparse=False,handle_unknown='ignore')   # convert to dummy variables\n",
        "feature_scaling = StandardScaler()  #feature scaling\n",
        "column_tranformer = make_column_transformer((feature_scaling, numerical_col), (ohe, categorical_col) , remainder='passthrough')\n",
        "\n",
        "#Training Set\n",
        "X_train1 = column_tranformer.fit_transform(X_train)\n",
        "\n",
        "#Validation Set\n",
        "X_val1 = column_tranformer.transform(X_val)\n",
        "\n",
        "#Testing Set\n",
        "X_test1 = column_tranformer.transform(X_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58phm2tJS0tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train1= pd.get_dummies(data=X_train, columns=categorical_col)    #get dummies for each categorical variables\n",
        "\n",
        "#Scale the numerical columns \n",
        "#ct = make_column_transformer((StandardScaler(), numerical_col), remainder= 'passthrough')        # scale the numerical features\n",
        "#X_train= ct.fit_transform(X_train1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtsJtzbgrtZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e371fd19-7c20-493f-c306-90b24a042813"
      },
      "source": [
        "print (f\"The data type of X_train: {type(X_train1)}\")\n",
        "print (f\" The data type of y_train: {type(y_train)}\" )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The data type of X_train: <class 'numpy.ndarray'>\n",
            " The data type of y_train: <class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLDsF57kShpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a function for model evaluation\n",
        "def generate_model_report(y_test, y_pred):\n",
        "  print(f\"Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
        "  print(f\"Precision: {precision_score(y_test,y_pred)}\")\n",
        "  print(f\"Recall: {recall_score(y_test,y_pred)}\")\n",
        "  print(f\"F1 Score: {f1_score(y_test,y_pred)}\")\n",
        "  pass"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znWNbMbns4_J",
        "colab_type": "text"
      },
      "source": [
        "**Create and Train the ANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9DtsfntsVEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "a8d30b39-169e-416b-a535-d769d53ae80c"
      },
      "source": [
        "ann = tf.keras.Sequential() #intialize the ANN\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=10, activation='relu')) # add the input and the first hidden layer\n",
        "\n",
        "#ann.add(tf.keras.layers.Dense(units=82, activation='relu')) # add second hidden layer\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))  #add the final output later\n",
        "\n",
        "ann.compile(optimizer='adam' , loss= 'binary_crossentropy', metrics=['accuracy'])      #compile the NN\n",
        "  \n",
        "ann.fit(X_train1,y_train, batch_size= 32 , epochs=10)\n",
        "\n",
        "print('*'*20)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Training Score and Accuracy\")\n",
        "score, acc = ann.evaluate(X_train1, y_train, batch_size=32)\n",
        "print('Train score:', score)\n",
        "print('Train accuracy:', acc)\n",
        "\n",
        "# Predicting the Validation set results\n",
        "y_pred = ann.predict(X_val1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "print('*'*20)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Validation Score and Accuracy\")\n",
        "score, acc = ann.evaluate(X_val1, y_val, batch_size=32)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print (\"Evaluation metrics\")\n",
        "\n",
        "generate_model_report(y_val, y_pred)\n",
        "  "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.3954 - accuracy: 0.8128\n",
            "Epoch 2/10\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3266 - accuracy: 0.8486\n",
            "Epoch 3/10\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3225 - accuracy: 0.8508\n",
            "Epoch 4/10\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3198 - accuracy: 0.8524\n",
            "Epoch 5/10\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3174 - accuracy: 0.8533\n",
            "Epoch 6/10\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3156 - accuracy: 0.8545\n",
            "Epoch 7/10\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3140 - accuracy: 0.8541\n",
            "Epoch 8/10\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3121 - accuracy: 0.8552\n",
            "Epoch 9/10\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3113 - accuracy: 0.8554\n",
            "Epoch 10/10\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3105 - accuracy: 0.8562\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3087 - accuracy: 0.8567\n",
            "Train score: 0.30874863266944885\n",
            "Train accuracy: 0.8567367196083069\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 0.3174 - accuracy: 0.8504\n",
            "Test score: 0.3173971474170685\n",
            "Test accuracy: 0.850361168384552\n",
            "\n",
            "\n",
            "Confusion Matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4757,  345],\n",
              "       [ 670, 1011]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i9DQQkjBpwJ",
        "colab_type": "text"
      },
      "source": [
        "**Train the ANN for different parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3686i9EBB3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf462486-9918-49c7-f335-116508a8d990"
      },
      "source": [
        "epochs = [50,100,150,200]    #randomly selected parameters\n",
        "input_units = [40,82,160]\n",
        "\n",
        "for epoch in epochs:\n",
        "    for unit in input_units:\n",
        "\n",
        "        ann = tf.keras.Sequential() #intialize the ANN\n",
        "\n",
        "        ann.add(tf.keras.layers.Dense(units=unit, activation='relu')) # add the input and the first hidden layer\n",
        "\n",
        "        ann.add(tf.keras.layers.Dense(units=unit, activation='relu')) # add second hidden layer\n",
        "\n",
        "        ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))  #add the final output later\n",
        "\n",
        "        ann.compile(optimizer='adam' , loss= 'binary_crossentropy', metrics=['accuracy'])      #compile the NN\n",
        "          \n",
        "        ann.fit(X_train1,y_train, batch_size= 32 , epochs=epoch)\n",
        "\n",
        "        print('*'*20)\n",
        "\n",
        "        print(\"\\n\")\n",
        "\n",
        "        print(f\"Training Score and Accuracy at epoch: {epoch} and unit: {unit}\")\n",
        "        score, acc = ann.evaluate(X_train1, y_train, batch_size=32)\n",
        "        print('Train score:', score)\n",
        "        print('Train accuracy:', acc)\n",
        "\n",
        "        # Predicting the Validation set results\n",
        "        y_pred = ann.predict(X_val1)\n",
        "        y_pred = (y_pred > 0.5)\n",
        "\n",
        "        print('*'*20)\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(f\"Validation Score and Accuracy at epoch: {epoch} and unit:{unit}\")\n",
        "        score, acc = ann.evaluate(X_val1, y_val, batch_size=32)\n",
        "        print('Test score:', score)\n",
        "        print('Test accuracy:', acc)\n",
        "        \n",
        "\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print (\"Model Evaluation Metrics\")\n",
        "        generate_model_report(y_val, y_pred)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3424 - accuracy: 0.8390\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3167 - accuracy: 0.8529\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3124 - accuracy: 0.8548\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3100 - accuracy: 0.8559\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3083 - accuracy: 0.8580\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3061 - accuracy: 0.8589\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3043 - accuracy: 0.8597\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3026 - accuracy: 0.8593\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3008 - accuracy: 0.8606\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2992 - accuracy: 0.8619\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2982 - accuracy: 0.8620\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2962 - accuracy: 0.8642\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2951 - accuracy: 0.8637\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2941 - accuracy: 0.8644\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2929 - accuracy: 0.8648\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2918 - accuracy: 0.8667\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2902 - accuracy: 0.8666\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2895 - accuracy: 0.8680\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2882 - accuracy: 0.8677\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2874 - accuracy: 0.8692\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2862 - accuracy: 0.8682\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2853 - accuracy: 0.8686\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2842 - accuracy: 0.8698\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2840 - accuracy: 0.8693\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2822 - accuracy: 0.8706\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2813 - accuracy: 0.8713\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2803 - accuracy: 0.8719\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2795 - accuracy: 0.8724\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2788 - accuracy: 0.8723\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2775 - accuracy: 0.8734\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2772 - accuracy: 0.8740\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2764 - accuracy: 0.8733\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2750 - accuracy: 0.8744\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2746 - accuracy: 0.8740\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2736 - accuracy: 0.8749\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2736 - accuracy: 0.8743\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2723 - accuracy: 0.8759\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2723 - accuracy: 0.8757\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2715 - accuracy: 0.8760\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2709 - accuracy: 0.8763\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2697 - accuracy: 0.8756\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.8749\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2685 - accuracy: 0.8764\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2682 - accuracy: 0.8759\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2674 - accuracy: 0.8773\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2670 - accuracy: 0.8769\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2662 - accuracy: 0.8785\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2659 - accuracy: 0.8774\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2656 - accuracy: 0.8780\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2644 - accuracy: 0.8802\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 50 and unit: 40\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2592 - accuracy: 0.8810\n",
            "Train score: 0.2592357099056244\n",
            "Train accuracy: 0.8809666633605957\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 50 and unit:40\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8449\n",
            "Test score: 0.3466174602508545\n",
            "Test accuracy: 0.8449063897132874\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8449063836060741\n",
            "Precision: 0.7297297297297297\n",
            "Recall: 0.5942891136228435\n",
            "F1 Score: 0.6550819672131147\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3331 - accuracy: 0.8438\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3152 - accuracy: 0.8541\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3107 - accuracy: 0.8550\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3076 - accuracy: 0.8577\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3049 - accuracy: 0.8601\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3019 - accuracy: 0.8615\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2986 - accuracy: 0.8636\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2968 - accuracy: 0.8643\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2939 - accuracy: 0.8662\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2916 - accuracy: 0.8668\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2887 - accuracy: 0.8683\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2861 - accuracy: 0.8698\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2838 - accuracy: 0.8704\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2810 - accuracy: 0.8733\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2793 - accuracy: 0.8723\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2762 - accuracy: 0.8733\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2745 - accuracy: 0.8740\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2719 - accuracy: 0.8754\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2688 - accuracy: 0.8763\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2667 - accuracy: 0.8777\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2644 - accuracy: 0.8786\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2619 - accuracy: 0.8806\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2602 - accuracy: 0.8800\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2587 - accuracy: 0.8823\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2558 - accuracy: 0.8830\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.2545 - accuracy: 0.8833\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 4s 4ms/step - loss: 0.2519 - accuracy: 0.8849\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 4s 4ms/step - loss: 0.2508 - accuracy: 0.8852\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.2489 - accuracy: 0.8849\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2472 - accuracy: 0.8861\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2454 - accuracy: 0.8874\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2434 - accuracy: 0.8890\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2424 - accuracy: 0.8891\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2402 - accuracy: 0.8906\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2380 - accuracy: 0.8901\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2372 - accuracy: 0.8911\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2361 - accuracy: 0.8918\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2341 - accuracy: 0.8938\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2321 - accuracy: 0.8936\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2305 - accuracy: 0.8942\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2296 - accuracy: 0.8933\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2278 - accuracy: 0.8965\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2262 - accuracy: 0.8950\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2256 - accuracy: 0.8967\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2238 - accuracy: 0.8974\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2236 - accuracy: 0.8977\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2215 - accuracy: 0.8976\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2199 - accuracy: 0.8981\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2185 - accuracy: 0.8997\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2169 - accuracy: 0.9006\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 50 and unit: 82\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2098 - accuracy: 0.9054\n",
            "Train score: 0.209839329123497\n",
            "Train accuracy: 0.9053546190261841\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 50 and unit:82\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.8333\n",
            "Test score: 0.4439426362514496\n",
            "Test accuracy: 0.833259642124176\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8332596196373286\n",
            "Precision: 0.6708074534161491\n",
            "Recall: 0.6424747174301011\n",
            "F1 Score: 0.6563354603463993\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3304 - accuracy: 0.8464\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3134 - accuracy: 0.8555\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3094 - accuracy: 0.8565\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3049 - accuracy: 0.8601\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3019 - accuracy: 0.8609\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2983 - accuracy: 0.8638\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2942 - accuracy: 0.8652\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2897 - accuracy: 0.8665\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2860 - accuracy: 0.8685\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2819 - accuracy: 0.8697\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2777 - accuracy: 0.8709\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2738 - accuracy: 0.8737\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2699 - accuracy: 0.8745\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2670 - accuracy: 0.8774\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2627 - accuracy: 0.8783\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2589 - accuracy: 0.8797\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2563 - accuracy: 0.8812\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2522 - accuracy: 0.8836\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2487 - accuracy: 0.8844\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2478 - accuracy: 0.8856\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2415 - accuracy: 0.8875\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2392 - accuracy: 0.8898\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2357 - accuracy: 0.8911\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2330 - accuracy: 0.8920\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2301 - accuracy: 0.8912\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2267 - accuracy: 0.8953\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2243 - accuracy: 0.8959\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2207 - accuracy: 0.8974\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2176 - accuracy: 0.8976\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2175 - accuracy: 0.8997\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2114 - accuracy: 0.9021\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2092 - accuracy: 0.9028\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2070 - accuracy: 0.9033\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2046 - accuracy: 0.9051\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2018 - accuracy: 0.9072\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1995 - accuracy: 0.9070\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1972 - accuracy: 0.9085\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1957 - accuracy: 0.9087\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1926 - accuracy: 0.9111\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1921 - accuracy: 0.9112\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1891 - accuracy: 0.9139\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1862 - accuracy: 0.9132\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1847 - accuracy: 0.9146\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1840 - accuracy: 0.9154\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1803 - accuracy: 0.9157\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1784 - accuracy: 0.9171\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1780 - accuracy: 0.9179\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1738 - accuracy: 0.9190\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1722 - accuracy: 0.9201\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1721 - accuracy: 0.9201\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 50 and unit: 160\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.1569 - accuracy: 0.9278\n",
            "Train score: 0.15686701238155365\n",
            "Train accuracy: 0.9278154969215393\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 50 and unit:160\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.8293\n",
            "Test score: 0.6568397879600525\n",
            "Test accuracy: 0.8292790651321411\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8292790800530738\n",
            "Precision: 0.6770480704129993\n",
            "Recall: 0.594883997620464\n",
            "F1 Score: 0.6333122229259024\n",
            "Epoch 1/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3467 - accuracy: 0.8352\n",
            "Epoch 2/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3167 - accuracy: 0.8532\n",
            "Epoch 3/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3124 - accuracy: 0.8553\n",
            "Epoch 4/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3099 - accuracy: 0.8568\n",
            "Epoch 5/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3071 - accuracy: 0.8587\n",
            "Epoch 6/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3046 - accuracy: 0.8594\n",
            "Epoch 7/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3030 - accuracy: 0.8596\n",
            "Epoch 8/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.3004 - accuracy: 0.8617\n",
            "Epoch 9/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2993 - accuracy: 0.8613\n",
            "Epoch 10/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2979 - accuracy: 0.8626\n",
            "Epoch 11/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2963 - accuracy: 0.8634\n",
            "Epoch 12/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2950 - accuracy: 0.8647\n",
            "Epoch 13/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2938 - accuracy: 0.8645\n",
            "Epoch 14/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2926 - accuracy: 0.8655\n",
            "Epoch 15/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2917 - accuracy: 0.8646\n",
            "Epoch 16/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2898 - accuracy: 0.8668\n",
            "Epoch 17/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2891 - accuracy: 0.8665\n",
            "Epoch 18/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2878 - accuracy: 0.8666\n",
            "Epoch 19/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2871 - accuracy: 0.8675\n",
            "Epoch 20/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2857 - accuracy: 0.8681\n",
            "Epoch 21/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2849 - accuracy: 0.8675\n",
            "Epoch 22/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2845 - accuracy: 0.8686\n",
            "Epoch 23/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2834 - accuracy: 0.8681\n",
            "Epoch 24/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2822 - accuracy: 0.8689\n",
            "Epoch 25/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2813 - accuracy: 0.8699\n",
            "Epoch 26/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2806 - accuracy: 0.8702\n",
            "Epoch 27/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2787 - accuracy: 0.8705\n",
            "Epoch 28/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2789 - accuracy: 0.8709\n",
            "Epoch 29/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2775 - accuracy: 0.8717\n",
            "Epoch 30/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2768 - accuracy: 0.8719\n",
            "Epoch 31/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2759 - accuracy: 0.8717\n",
            "Epoch 32/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2754 - accuracy: 0.8720\n",
            "Epoch 33/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2743 - accuracy: 0.8728\n",
            "Epoch 34/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2729 - accuracy: 0.8728\n",
            "Epoch 35/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2727 - accuracy: 0.8739\n",
            "Epoch 36/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2717 - accuracy: 0.8733\n",
            "Epoch 37/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2708 - accuracy: 0.8747\n",
            "Epoch 38/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2699 - accuracy: 0.8750\n",
            "Epoch 39/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2695 - accuracy: 0.8754\n",
            "Epoch 40/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2679 - accuracy: 0.8759\n",
            "Epoch 41/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2673 - accuracy: 0.8752\n",
            "Epoch 42/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2666 - accuracy: 0.8758\n",
            "Epoch 43/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2661 - accuracy: 0.8760\n",
            "Epoch 44/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2663 - accuracy: 0.8769\n",
            "Epoch 45/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2648 - accuracy: 0.8768\n",
            "Epoch 46/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2644 - accuracy: 0.8780\n",
            "Epoch 47/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2633 - accuracy: 0.8774\n",
            "Epoch 48/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2631 - accuracy: 0.8771\n",
            "Epoch 49/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2628 - accuracy: 0.8771\n",
            "Epoch 50/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2619 - accuracy: 0.8782\n",
            "Epoch 51/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2613 - accuracy: 0.8793\n",
            "Epoch 52/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2605 - accuracy: 0.8801\n",
            "Epoch 53/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2606 - accuracy: 0.8790\n",
            "Epoch 54/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2592 - accuracy: 0.8783\n",
            "Epoch 55/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2588 - accuracy: 0.8800\n",
            "Epoch 56/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2584 - accuracy: 0.8798\n",
            "Epoch 57/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2578 - accuracy: 0.8812\n",
            "Epoch 58/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2573 - accuracy: 0.8786\n",
            "Epoch 59/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2569 - accuracy: 0.8817\n",
            "Epoch 60/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2562 - accuracy: 0.8812\n",
            "Epoch 61/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2556 - accuracy: 0.8826\n",
            "Epoch 62/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2551 - accuracy: 0.8816\n",
            "Epoch 63/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2549 - accuracy: 0.8825\n",
            "Epoch 64/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2543 - accuracy: 0.8819\n",
            "Epoch 65/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2540 - accuracy: 0.8819\n",
            "Epoch 66/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2533 - accuracy: 0.8830\n",
            "Epoch 67/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2530 - accuracy: 0.8832\n",
            "Epoch 68/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2535 - accuracy: 0.8827\n",
            "Epoch 69/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2523 - accuracy: 0.8840\n",
            "Epoch 70/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2517 - accuracy: 0.8836\n",
            "Epoch 71/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2517 - accuracy: 0.8833\n",
            "Epoch 72/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2510 - accuracy: 0.8846\n",
            "Epoch 73/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2501 - accuracy: 0.8843\n",
            "Epoch 74/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2500 - accuracy: 0.8840\n",
            "Epoch 75/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2492 - accuracy: 0.8850\n",
            "Epoch 76/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.8846\n",
            "Epoch 77/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.8837\n",
            "Epoch 78/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2479 - accuracy: 0.8843\n",
            "Epoch 79/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2477 - accuracy: 0.8839\n",
            "Epoch 80/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2470 - accuracy: 0.8861\n",
            "Epoch 81/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2472 - accuracy: 0.8854\n",
            "Epoch 82/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2464 - accuracy: 0.8871\n",
            "Epoch 83/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2461 - accuracy: 0.8860\n",
            "Epoch 84/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2461 - accuracy: 0.8848\n",
            "Epoch 85/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2460 - accuracy: 0.8849\n",
            "Epoch 86/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2459 - accuracy: 0.8860\n",
            "Epoch 87/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2449 - accuracy: 0.8872\n",
            "Epoch 88/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2450 - accuracy: 0.8858\n",
            "Epoch 89/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2438 - accuracy: 0.8862\n",
            "Epoch 90/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2435 - accuracy: 0.8878\n",
            "Epoch 91/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2446 - accuracy: 0.8856\n",
            "Epoch 92/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2440 - accuracy: 0.8867\n",
            "Epoch 93/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2424 - accuracy: 0.8873\n",
            "Epoch 94/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2416 - accuracy: 0.8883\n",
            "Epoch 95/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2416 - accuracy: 0.8873\n",
            "Epoch 96/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2425 - accuracy: 0.8876\n",
            "Epoch 97/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2411 - accuracy: 0.8877\n",
            "Epoch 98/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2403 - accuracy: 0.8889\n",
            "Epoch 99/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2417 - accuracy: 0.8881\n",
            "Epoch 100/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2417 - accuracy: 0.8871\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 100 and unit: 40\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2330 - accuracy: 0.8922\n",
            "Train score: 0.23301199078559875\n",
            "Train accuracy: 0.8922445178031921\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 100 and unit:40\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8396\n",
            "Test score: 0.41655606031417847\n",
            "Test accuracy: 0.8395990133285522\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8395989974937343\n",
            "Precision: 0.6906752411575563\n",
            "Recall: 0.6389054134443783\n",
            "F1 Score: 0.6637824474660075\n",
            "Epoch 1/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3348 - accuracy: 0.8455\n",
            "Epoch 2/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3143 - accuracy: 0.8549\n",
            "Epoch 3/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3106 - accuracy: 0.8579\n",
            "Epoch 4/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3070 - accuracy: 0.8569\n",
            "Epoch 5/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3036 - accuracy: 0.8602\n",
            "Epoch 6/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3006 - accuracy: 0.8613\n",
            "Epoch 7/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2978 - accuracy: 0.8619\n",
            "Epoch 8/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2959 - accuracy: 0.8656\n",
            "Epoch 9/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2926 - accuracy: 0.8670\n",
            "Epoch 10/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2899 - accuracy: 0.8661\n",
            "Epoch 11/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2873 - accuracy: 0.8680\n",
            "Epoch 12/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2842 - accuracy: 0.8698\n",
            "Epoch 13/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2820 - accuracy: 0.8699\n",
            "Epoch 14/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2794 - accuracy: 0.8714\n",
            "Epoch 15/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2769 - accuracy: 0.8721\n",
            "Epoch 16/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2745 - accuracy: 0.8730\n",
            "Epoch 17/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2727 - accuracy: 0.8748\n",
            "Epoch 18/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2694 - accuracy: 0.8757\n",
            "Epoch 19/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2683 - accuracy: 0.8767\n",
            "Epoch 20/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2647 - accuracy: 0.8789\n",
            "Epoch 21/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2631 - accuracy: 0.8790\n",
            "Epoch 22/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2610 - accuracy: 0.8796\n",
            "Epoch 23/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2591 - accuracy: 0.8801\n",
            "Epoch 24/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2573 - accuracy: 0.8807\n",
            "Epoch 25/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2553 - accuracy: 0.8827\n",
            "Epoch 26/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2524 - accuracy: 0.8836\n",
            "Epoch 27/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2507 - accuracy: 0.8861\n",
            "Epoch 28/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2488 - accuracy: 0.8866\n",
            "Epoch 29/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2477 - accuracy: 0.8862\n",
            "Epoch 30/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2456 - accuracy: 0.8866\n",
            "Epoch 31/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2428 - accuracy: 0.8891\n",
            "Epoch 32/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2417 - accuracy: 0.8883\n",
            "Epoch 33/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2398 - accuracy: 0.8891\n",
            "Epoch 34/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2385 - accuracy: 0.8903\n",
            "Epoch 35/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2360 - accuracy: 0.8907\n",
            "Epoch 36/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2343 - accuracy: 0.8913\n",
            "Epoch 37/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2327 - accuracy: 0.8939\n",
            "Epoch 38/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2328 - accuracy: 0.8927\n",
            "Epoch 39/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2296 - accuracy: 0.8949\n",
            "Epoch 40/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2283 - accuracy: 0.8951\n",
            "Epoch 41/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2269 - accuracy: 0.8943\n",
            "Epoch 42/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2256 - accuracy: 0.8967\n",
            "Epoch 43/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2241 - accuracy: 0.8969\n",
            "Epoch 44/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2221 - accuracy: 0.8987\n",
            "Epoch 45/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2219 - accuracy: 0.8978\n",
            "Epoch 46/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2192 - accuracy: 0.8989\n",
            "Epoch 47/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2180 - accuracy: 0.9008\n",
            "Epoch 48/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2162 - accuracy: 0.9012\n",
            "Epoch 49/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2168 - accuracy: 0.9006\n",
            "Epoch 50/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2138 - accuracy: 0.9016\n",
            "Epoch 51/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2137 - accuracy: 0.9009\n",
            "Epoch 52/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2113 - accuracy: 0.9030\n",
            "Epoch 53/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2097 - accuracy: 0.9037\n",
            "Epoch 54/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2092 - accuracy: 0.9050\n",
            "Epoch 55/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2083 - accuracy: 0.9034\n",
            "Epoch 56/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2068 - accuracy: 0.9058\n",
            "Epoch 57/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2078 - accuracy: 0.9048\n",
            "Epoch 58/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2042 - accuracy: 0.9056\n",
            "Epoch 59/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2020 - accuracy: 0.9081\n",
            "Epoch 60/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2015 - accuracy: 0.9073\n",
            "Epoch 61/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2014 - accuracy: 0.9069\n",
            "Epoch 62/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2005 - accuracy: 0.9080\n",
            "Epoch 63/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1990 - accuracy: 0.9082\n",
            "Epoch 64/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2003 - accuracy: 0.9085\n",
            "Epoch 65/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1965 - accuracy: 0.9106\n",
            "Epoch 66/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1952 - accuracy: 0.9096\n",
            "Epoch 67/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1952 - accuracy: 0.9104\n",
            "Epoch 68/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1943 - accuracy: 0.9115\n",
            "Epoch 69/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1924 - accuracy: 0.9128\n",
            "Epoch 70/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1925 - accuracy: 0.9120\n",
            "Epoch 71/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1910 - accuracy: 0.9116\n",
            "Epoch 72/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1893 - accuracy: 0.9134\n",
            "Epoch 73/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1898 - accuracy: 0.9131\n",
            "Epoch 74/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1887 - accuracy: 0.9132\n",
            "Epoch 75/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1878 - accuracy: 0.9131\n",
            "Epoch 76/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1870 - accuracy: 0.9133\n",
            "Epoch 77/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1853 - accuracy: 0.9153\n",
            "Epoch 78/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1850 - accuracy: 0.9153\n",
            "Epoch 79/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1842 - accuracy: 0.9150\n",
            "Epoch 80/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1825 - accuracy: 0.9160\n",
            "Epoch 81/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1829 - accuracy: 0.9154\n",
            "Epoch 82/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1844 - accuracy: 0.9163\n",
            "Epoch 83/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1803 - accuracy: 0.9181\n",
            "Epoch 84/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1792 - accuracy: 0.9181\n",
            "Epoch 85/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1788 - accuracy: 0.9174\n",
            "Epoch 86/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1793 - accuracy: 0.9165\n",
            "Epoch 87/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1773 - accuracy: 0.9187\n",
            "Epoch 88/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1771 - accuracy: 0.9185\n",
            "Epoch 89/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1767 - accuracy: 0.9187\n",
            "Epoch 90/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1766 - accuracy: 0.9185\n",
            "Epoch 91/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1733 - accuracy: 0.9208\n",
            "Epoch 92/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1744 - accuracy: 0.9199\n",
            "Epoch 93/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1731 - accuracy: 0.9208\n",
            "Epoch 94/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1726 - accuracy: 0.9205\n",
            "Epoch 95/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1714 - accuracy: 0.9208\n",
            "Epoch 96/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1719 - accuracy: 0.9211\n",
            "Epoch 97/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1723 - accuracy: 0.9210\n",
            "Epoch 98/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1686 - accuracy: 0.9233\n",
            "Epoch 99/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1685 - accuracy: 0.9234\n",
            "Epoch 100/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1679 - accuracy: 0.9230\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 100 and unit: 82\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.1575 - accuracy: 0.9290\n",
            "Train score: 0.1575147807598114\n",
            "Train accuracy: 0.9289843440055847\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 100 and unit:82\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.8235\n",
            "Test score: 0.6753606200218201\n",
            "Test accuracy: 0.8235294222831726\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8235294117647058\n",
            "Precision: 0.6678224687933426\n",
            "Recall: 0.5728732897085068\n",
            "F1 Score: 0.61671469740634\n",
            "Epoch 1/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3299 - accuracy: 0.8444\n",
            "Epoch 2/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3144 - accuracy: 0.8549\n",
            "Epoch 3/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3093 - accuracy: 0.8577\n",
            "Epoch 4/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3066 - accuracy: 0.8587\n",
            "Epoch 5/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3019 - accuracy: 0.8618\n",
            "Epoch 6/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2986 - accuracy: 0.8627\n",
            "Epoch 7/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2946 - accuracy: 0.8653\n",
            "Epoch 8/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2904 - accuracy: 0.8656\n",
            "Epoch 9/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2868 - accuracy: 0.8668\n",
            "Epoch 10/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2832 - accuracy: 0.8687\n",
            "Epoch 11/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2792 - accuracy: 0.8704\n",
            "Epoch 12/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2754 - accuracy: 0.8730\n",
            "Epoch 13/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2711 - accuracy: 0.8741\n",
            "Epoch 14/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2680 - accuracy: 0.8756\n",
            "Epoch 15/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2641 - accuracy: 0.8777\n",
            "Epoch 16/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2599 - accuracy: 0.8791\n",
            "Epoch 17/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2567 - accuracy: 0.8809\n",
            "Epoch 18/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2531 - accuracy: 0.8812\n",
            "Epoch 19/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2495 - accuracy: 0.8843\n",
            "Epoch 20/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2469 - accuracy: 0.8859\n",
            "Epoch 21/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2428 - accuracy: 0.8866\n",
            "Epoch 22/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2395 - accuracy: 0.8880\n",
            "Epoch 23/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2367 - accuracy: 0.8896\n",
            "Epoch 24/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2332 - accuracy: 0.8908\n",
            "Epoch 25/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2304 - accuracy: 0.8921\n",
            "Epoch 26/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2272 - accuracy: 0.8942\n",
            "Epoch 27/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2238 - accuracy: 0.8953\n",
            "Epoch 28/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2204 - accuracy: 0.8981\n",
            "Epoch 29/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2177 - accuracy: 0.8986\n",
            "Epoch 30/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2148 - accuracy: 0.8991\n",
            "Epoch 31/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2126 - accuracy: 0.9011\n",
            "Epoch 32/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2093 - accuracy: 0.9029\n",
            "Epoch 33/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2083 - accuracy: 0.9025\n",
            "Epoch 34/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2063 - accuracy: 0.9049\n",
            "Epoch 35/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2037 - accuracy: 0.9054\n",
            "Epoch 36/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1995 - accuracy: 0.9079\n",
            "Epoch 37/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1977 - accuracy: 0.9076\n",
            "Epoch 38/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1965 - accuracy: 0.9094\n",
            "Epoch 39/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1937 - accuracy: 0.9102\n",
            "Epoch 40/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1918 - accuracy: 0.9105\n",
            "Epoch 41/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1888 - accuracy: 0.9115\n",
            "Epoch 42/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1863 - accuracy: 0.9141\n",
            "Epoch 43/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1878 - accuracy: 0.9135\n",
            "Epoch 44/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1843 - accuracy: 0.9149\n",
            "Epoch 45/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1801 - accuracy: 0.9169\n",
            "Epoch 46/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1796 - accuracy: 0.9164\n",
            "Epoch 47/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1779 - accuracy: 0.9179\n",
            "Epoch 48/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1762 - accuracy: 0.9192\n",
            "Epoch 49/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1738 - accuracy: 0.9205\n",
            "Epoch 50/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1728 - accuracy: 0.9190\n",
            "Epoch 51/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1711 - accuracy: 0.9207\n",
            "Epoch 52/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1702 - accuracy: 0.9220\n",
            "Epoch 53/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1677 - accuracy: 0.9217\n",
            "Epoch 54/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1666 - accuracy: 0.9227\n",
            "Epoch 55/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1640 - accuracy: 0.9242\n",
            "Epoch 56/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1620 - accuracy: 0.9244\n",
            "Epoch 57/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1629 - accuracy: 0.9257\n",
            "Epoch 58/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1618 - accuracy: 0.9262\n",
            "Epoch 59/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1573 - accuracy: 0.9279\n",
            "Epoch 60/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1565 - accuracy: 0.9279\n",
            "Epoch 61/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1554 - accuracy: 0.9284\n",
            "Epoch 62/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1560 - accuracy: 0.9285\n",
            "Epoch 63/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1519 - accuracy: 0.9304\n",
            "Epoch 64/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1511 - accuracy: 0.9301\n",
            "Epoch 65/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1527 - accuracy: 0.9290\n",
            "Epoch 66/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1488 - accuracy: 0.9308\n",
            "Epoch 67/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1491 - accuracy: 0.9330\n",
            "Epoch 68/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1454 - accuracy: 0.9330\n",
            "Epoch 69/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1464 - accuracy: 0.9324\n",
            "Epoch 70/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1450 - accuracy: 0.9332\n",
            "Epoch 71/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1435 - accuracy: 0.9350\n",
            "Epoch 72/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1428 - accuracy: 0.9345\n",
            "Epoch 73/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1417 - accuracy: 0.9356\n",
            "Epoch 74/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1421 - accuracy: 0.9350\n",
            "Epoch 75/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1393 - accuracy: 0.9348\n",
            "Epoch 76/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1378 - accuracy: 0.9348\n",
            "Epoch 77/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1427 - accuracy: 0.9348\n",
            "Epoch 78/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1365 - accuracy: 0.9382\n",
            "Epoch 79/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1354 - accuracy: 0.9382\n",
            "Epoch 80/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1331 - accuracy: 0.9384\n",
            "Epoch 81/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1329 - accuracy: 0.9385\n",
            "Epoch 82/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1339 - accuracy: 0.9385\n",
            "Epoch 83/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1332 - accuracy: 0.9397\n",
            "Epoch 84/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1311 - accuracy: 0.9405\n",
            "Epoch 85/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1301 - accuracy: 0.9407\n",
            "Epoch 86/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1313 - accuracy: 0.9400\n",
            "Epoch 87/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1271 - accuracy: 0.9419\n",
            "Epoch 88/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1270 - accuracy: 0.9423\n",
            "Epoch 89/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1267 - accuracy: 0.9423\n",
            "Epoch 90/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1261 - accuracy: 0.9422\n",
            "Epoch 91/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1253 - accuracy: 0.9426\n",
            "Epoch 92/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1252 - accuracy: 0.9441\n",
            "Epoch 93/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1228 - accuracy: 0.9454\n",
            "Epoch 94/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1265 - accuracy: 0.9432\n",
            "Epoch 95/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1201 - accuracy: 0.9446\n",
            "Epoch 96/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1217 - accuracy: 0.9446\n",
            "Epoch 97/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1197 - accuracy: 0.9454\n",
            "Epoch 98/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1194 - accuracy: 0.9447\n",
            "Epoch 99/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1210 - accuracy: 0.9453\n",
            "Epoch 100/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1166 - accuracy: 0.9472\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 100 and unit: 160\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.1080 - accuracy: 0.9521\n",
            "Train score: 0.10797368735074997\n",
            "Train accuracy: 0.9521402716636658\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 100 and unit:160\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 1.0600 - accuracy: 0.8222\n",
            "Test score: 1.0600330829620361\n",
            "Test accuracy: 0.8222025632858276\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8222025652366209\n",
            "Precision: 0.6492771841609051\n",
            "Recall: 0.6145151695419393\n",
            "F1 Score: 0.6314180929095354\n",
            "Epoch 1/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3398 - accuracy: 0.8412\n",
            "Epoch 2/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3164 - accuracy: 0.8521\n",
            "Epoch 3/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3135 - accuracy: 0.8542\n",
            "Epoch 4/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3100 - accuracy: 0.8578\n",
            "Epoch 5/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3072 - accuracy: 0.8587\n",
            "Epoch 6/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3052 - accuracy: 0.8591\n",
            "Epoch 7/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3035 - accuracy: 0.8604\n",
            "Epoch 8/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3016 - accuracy: 0.8612\n",
            "Epoch 9/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3000 - accuracy: 0.8627\n",
            "Epoch 10/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2985 - accuracy: 0.8624\n",
            "Epoch 11/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2970 - accuracy: 0.8625\n",
            "Epoch 12/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2947 - accuracy: 0.8631\n",
            "Epoch 13/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2938 - accuracy: 0.8648\n",
            "Epoch 14/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2929 - accuracy: 0.8652\n",
            "Epoch 15/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2916 - accuracy: 0.8652\n",
            "Epoch 16/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2902 - accuracy: 0.8659\n",
            "Epoch 17/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2885 - accuracy: 0.8668\n",
            "Epoch 18/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2876 - accuracy: 0.8686\n",
            "Epoch 19/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2863 - accuracy: 0.8683\n",
            "Epoch 20/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2850 - accuracy: 0.8698\n",
            "Epoch 21/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2848 - accuracy: 0.8694\n",
            "Epoch 22/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.8689\n",
            "Epoch 23/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2821 - accuracy: 0.8709\n",
            "Epoch 24/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2808 - accuracy: 0.8717\n",
            "Epoch 25/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2795 - accuracy: 0.8718\n",
            "Epoch 26/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2792 - accuracy: 0.8715\n",
            "Epoch 27/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2780 - accuracy: 0.8727\n",
            "Epoch 28/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2772 - accuracy: 0.8731\n",
            "Epoch 29/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2760 - accuracy: 0.8746\n",
            "Epoch 30/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2751 - accuracy: 0.8737\n",
            "Epoch 31/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2742 - accuracy: 0.8747\n",
            "Epoch 32/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2737 - accuracy: 0.8740\n",
            "Epoch 33/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2728 - accuracy: 0.8748\n",
            "Epoch 34/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2721 - accuracy: 0.8746\n",
            "Epoch 35/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2714 - accuracy: 0.8756\n",
            "Epoch 36/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.8757\n",
            "Epoch 37/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.8755\n",
            "Epoch 38/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2690 - accuracy: 0.8757\n",
            "Epoch 39/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2685 - accuracy: 0.8770\n",
            "Epoch 40/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2682 - accuracy: 0.8773\n",
            "Epoch 41/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2677 - accuracy: 0.8780\n",
            "Epoch 42/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2674 - accuracy: 0.8769\n",
            "Epoch 43/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2666 - accuracy: 0.8773\n",
            "Epoch 44/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2647 - accuracy: 0.8784\n",
            "Epoch 45/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2658 - accuracy: 0.8779\n",
            "Epoch 46/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2642 - accuracy: 0.8783\n",
            "Epoch 47/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2638 - accuracy: 0.8788\n",
            "Epoch 48/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2641 - accuracy: 0.8783\n",
            "Epoch 49/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2629 - accuracy: 0.8804\n",
            "Epoch 50/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2627 - accuracy: 0.8792\n",
            "Epoch 51/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2626 - accuracy: 0.8800\n",
            "Epoch 52/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2611 - accuracy: 0.8810\n",
            "Epoch 53/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2609 - accuracy: 0.8802\n",
            "Epoch 54/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2608 - accuracy: 0.8809\n",
            "Epoch 55/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2593 - accuracy: 0.8813\n",
            "Epoch 56/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2595 - accuracy: 0.8816\n",
            "Epoch 57/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2586 - accuracy: 0.8813\n",
            "Epoch 58/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2585 - accuracy: 0.8815\n",
            "Epoch 59/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2578 - accuracy: 0.8813\n",
            "Epoch 60/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2574 - accuracy: 0.8817\n",
            "Epoch 61/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2569 - accuracy: 0.8818\n",
            "Epoch 62/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2563 - accuracy: 0.8819\n",
            "Epoch 63/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2563 - accuracy: 0.8820\n",
            "Epoch 64/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2560 - accuracy: 0.8831\n",
            "Epoch 65/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2555 - accuracy: 0.8835\n",
            "Epoch 66/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2544 - accuracy: 0.8834\n",
            "Epoch 67/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2545 - accuracy: 0.8822\n",
            "Epoch 68/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.8841\n",
            "Epoch 69/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2538 - accuracy: 0.8831\n",
            "Epoch 70/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2534 - accuracy: 0.8837\n",
            "Epoch 71/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2534 - accuracy: 0.8834\n",
            "Epoch 72/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2525 - accuracy: 0.8831\n",
            "Epoch 73/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2529 - accuracy: 0.8834\n",
            "Epoch 74/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2511 - accuracy: 0.8838\n",
            "Epoch 75/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2517 - accuracy: 0.8846\n",
            "Epoch 76/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2513 - accuracy: 0.8852\n",
            "Epoch 77/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.8840\n",
            "Epoch 78/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2505 - accuracy: 0.8852\n",
            "Epoch 79/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2495 - accuracy: 0.8848\n",
            "Epoch 80/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2495 - accuracy: 0.8858\n",
            "Epoch 81/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2494 - accuracy: 0.8855\n",
            "Epoch 82/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2489 - accuracy: 0.8860\n",
            "Epoch 83/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2490 - accuracy: 0.8851\n",
            "Epoch 84/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2480 - accuracy: 0.8849\n",
            "Epoch 85/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2480 - accuracy: 0.8861\n",
            "Epoch 86/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2477 - accuracy: 0.8867\n",
            "Epoch 87/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2475 - accuracy: 0.8862\n",
            "Epoch 88/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2469 - accuracy: 0.8856\n",
            "Epoch 89/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2470 - accuracy: 0.8875\n",
            "Epoch 90/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2457 - accuracy: 0.8870\n",
            "Epoch 91/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2463 - accuracy: 0.8870\n",
            "Epoch 92/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2455 - accuracy: 0.8872\n",
            "Epoch 93/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2457 - accuracy: 0.8862\n",
            "Epoch 94/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.8870\n",
            "Epoch 95/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2446 - accuracy: 0.8872\n",
            "Epoch 96/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2453 - accuracy: 0.8873\n",
            "Epoch 97/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2444 - accuracy: 0.8885\n",
            "Epoch 98/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2437 - accuracy: 0.8883\n",
            "Epoch 99/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2441 - accuracy: 0.8877\n",
            "Epoch 100/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2426 - accuracy: 0.8885\n",
            "Epoch 101/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2427 - accuracy: 0.8889\n",
            "Epoch 102/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.8886\n",
            "Epoch 103/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2421 - accuracy: 0.8894\n",
            "Epoch 104/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2411 - accuracy: 0.8889\n",
            "Epoch 105/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2415 - accuracy: 0.8897\n",
            "Epoch 106/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2408 - accuracy: 0.8888\n",
            "Epoch 107/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2412 - accuracy: 0.8889\n",
            "Epoch 108/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2400 - accuracy: 0.8902\n",
            "Epoch 109/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2412 - accuracy: 0.8890\n",
            "Epoch 110/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2409 - accuracy: 0.8885\n",
            "Epoch 111/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2402 - accuracy: 0.8895\n",
            "Epoch 112/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2392 - accuracy: 0.8892\n",
            "Epoch 113/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2401 - accuracy: 0.8891\n",
            "Epoch 114/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2394 - accuracy: 0.8895\n",
            "Epoch 115/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2393 - accuracy: 0.8907\n",
            "Epoch 116/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2389 - accuracy: 0.8893\n",
            "Epoch 117/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2384 - accuracy: 0.8891\n",
            "Epoch 118/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2388 - accuracy: 0.8910\n",
            "Epoch 119/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2384 - accuracy: 0.8899\n",
            "Epoch 120/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2384 - accuracy: 0.8903\n",
            "Epoch 121/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2373 - accuracy: 0.8904\n",
            "Epoch 122/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2374 - accuracy: 0.8906\n",
            "Epoch 123/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2374 - accuracy: 0.8909\n",
            "Epoch 124/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2366 - accuracy: 0.8919\n",
            "Epoch 125/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2361 - accuracy: 0.8906\n",
            "Epoch 126/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2356 - accuracy: 0.8911\n",
            "Epoch 127/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2363 - accuracy: 0.8917\n",
            "Epoch 128/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2358 - accuracy: 0.8921\n",
            "Epoch 129/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2352 - accuracy: 0.8916\n",
            "Epoch 130/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2349 - accuracy: 0.8920\n",
            "Epoch 131/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2353 - accuracy: 0.8913\n",
            "Epoch 132/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2344 - accuracy: 0.8915\n",
            "Epoch 133/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2344 - accuracy: 0.8936\n",
            "Epoch 134/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2346 - accuracy: 0.8928\n",
            "Epoch 135/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2340 - accuracy: 0.8927\n",
            "Epoch 136/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2336 - accuracy: 0.8917\n",
            "Epoch 137/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2332 - accuracy: 0.8915\n",
            "Epoch 138/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2327 - accuracy: 0.8924\n",
            "Epoch 139/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2336 - accuracy: 0.8931\n",
            "Epoch 140/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2332 - accuracy: 0.8920\n",
            "Epoch 141/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2325 - accuracy: 0.8938\n",
            "Epoch 142/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2327 - accuracy: 0.8933\n",
            "Epoch 143/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2331 - accuracy: 0.8927\n",
            "Epoch 144/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2320 - accuracy: 0.8938\n",
            "Epoch 145/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2324 - accuracy: 0.8927\n",
            "Epoch 146/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2311 - accuracy: 0.8930\n",
            "Epoch 147/150\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2326 - accuracy: 0.8928\n",
            "Epoch 148/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2324 - accuracy: 0.8921\n",
            "Epoch 149/150\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2307 - accuracy: 0.8934\n",
            "Epoch 150/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2315 - accuracy: 0.8941\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 150 and unit: 40\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2237 - accuracy: 0.8974\n",
            "Train score: 0.2236766219139099\n",
            "Train accuracy: 0.8973937630653381\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 150 and unit:40\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.8359\n",
            "Test score: 0.44183823466300964\n",
            "Test accuracy: 0.8359133005142212\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8359133126934984\n",
            "Precision: 0.6875825627476883\n",
            "Recall: 0.619274241522903\n",
            "F1 Score: 0.651643192488263\n",
            "Epoch 1/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3366 - accuracy: 0.8438\n",
            "Epoch 2/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3148 - accuracy: 0.8543\n",
            "Epoch 3/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3099 - accuracy: 0.8565\n",
            "Epoch 4/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3067 - accuracy: 0.8588\n",
            "Epoch 5/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3040 - accuracy: 0.8604\n",
            "Epoch 6/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3013 - accuracy: 0.8623\n",
            "Epoch 7/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2986 - accuracy: 0.8649\n",
            "Epoch 8/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2959 - accuracy: 0.8638\n",
            "Epoch 9/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2930 - accuracy: 0.8652\n",
            "Epoch 10/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2912 - accuracy: 0.8669\n",
            "Epoch 11/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2891 - accuracy: 0.8674\n",
            "Epoch 12/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2874 - accuracy: 0.8674\n",
            "Epoch 13/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2848 - accuracy: 0.8695\n",
            "Epoch 14/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2830 - accuracy: 0.8702\n",
            "Epoch 15/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2799 - accuracy: 0.8710\n",
            "Epoch 16/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2787 - accuracy: 0.8707\n",
            "Epoch 17/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2758 - accuracy: 0.8741\n",
            "Epoch 18/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2740 - accuracy: 0.8737\n",
            "Epoch 19/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2722 - accuracy: 0.8752\n",
            "Epoch 20/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2705 - accuracy: 0.8759\n",
            "Epoch 21/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2687 - accuracy: 0.8764\n",
            "Epoch 22/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2667 - accuracy: 0.8778\n",
            "Epoch 23/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2655 - accuracy: 0.8771\n",
            "Epoch 24/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2629 - accuracy: 0.8800\n",
            "Epoch 25/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2613 - accuracy: 0.8794\n",
            "Epoch 26/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2593 - accuracy: 0.8802\n",
            "Epoch 27/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2589 - accuracy: 0.8801\n",
            "Epoch 28/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2563 - accuracy: 0.8826\n",
            "Epoch 29/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2545 - accuracy: 0.8829\n",
            "Epoch 30/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2525 - accuracy: 0.8845\n",
            "Epoch 31/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2512 - accuracy: 0.8848\n",
            "Epoch 32/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2497 - accuracy: 0.8854\n",
            "Epoch 33/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2485 - accuracy: 0.8853\n",
            "Epoch 34/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2464 - accuracy: 0.8868\n",
            "Epoch 35/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2445 - accuracy: 0.8872\n",
            "Epoch 36/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2436 - accuracy: 0.8886\n",
            "Epoch 37/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2416 - accuracy: 0.8898\n",
            "Epoch 38/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2403 - accuracy: 0.8904\n",
            "Epoch 39/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2393 - accuracy: 0.8912\n",
            "Epoch 40/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2367 - accuracy: 0.8905\n",
            "Epoch 41/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2355 - accuracy: 0.8903\n",
            "Epoch 42/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2344 - accuracy: 0.8915\n",
            "Epoch 43/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2325 - accuracy: 0.8932\n",
            "Epoch 44/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2308 - accuracy: 0.8922\n",
            "Epoch 45/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2305 - accuracy: 0.8939\n",
            "Epoch 46/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2279 - accuracy: 0.8944\n",
            "Epoch 47/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2270 - accuracy: 0.8952\n",
            "Epoch 48/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2253 - accuracy: 0.8959\n",
            "Epoch 49/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2248 - accuracy: 0.8965\n",
            "Epoch 50/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2230 - accuracy: 0.8971\n",
            "Epoch 51/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2210 - accuracy: 0.8966\n",
            "Epoch 52/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2212 - accuracy: 0.8983\n",
            "Epoch 53/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2188 - accuracy: 0.8984\n",
            "Epoch 54/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2210 - accuracy: 0.8993\n",
            "Epoch 55/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2180 - accuracy: 0.8997\n",
            "Epoch 56/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2144 - accuracy: 0.9013\n",
            "Epoch 57/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2139 - accuracy: 0.9014\n",
            "Epoch 58/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2127 - accuracy: 0.9013\n",
            "Epoch 59/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2115 - accuracy: 0.9024\n",
            "Epoch 60/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2103 - accuracy: 0.9020\n",
            "Epoch 61/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2096 - accuracy: 0.9038\n",
            "Epoch 62/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2087 - accuracy: 0.9036\n",
            "Epoch 63/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2068 - accuracy: 0.9044\n",
            "Epoch 64/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2062 - accuracy: 0.9050\n",
            "Epoch 65/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2058 - accuracy: 0.9046\n",
            "Epoch 66/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2040 - accuracy: 0.9044\n",
            "Epoch 67/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2029 - accuracy: 0.9055\n",
            "Epoch 68/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2020 - accuracy: 0.9061\n",
            "Epoch 69/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2009 - accuracy: 0.9067\n",
            "Epoch 70/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1992 - accuracy: 0.9072\n",
            "Epoch 71/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1988 - accuracy: 0.9077\n",
            "Epoch 72/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1985 - accuracy: 0.9084\n",
            "Epoch 73/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1968 - accuracy: 0.9093\n",
            "Epoch 74/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1983 - accuracy: 0.9081\n",
            "Epoch 75/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1955 - accuracy: 0.9100\n",
            "Epoch 76/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1934 - accuracy: 0.9104\n",
            "Epoch 77/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1928 - accuracy: 0.9117\n",
            "Epoch 78/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1917 - accuracy: 0.9126\n",
            "Epoch 79/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1903 - accuracy: 0.9118\n",
            "Epoch 80/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1904 - accuracy: 0.9115\n",
            "Epoch 81/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1890 - accuracy: 0.9124\n",
            "Epoch 82/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1881 - accuracy: 0.9145\n",
            "Epoch 83/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1900 - accuracy: 0.9127\n",
            "Epoch 84/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1865 - accuracy: 0.9137\n",
            "Epoch 85/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1862 - accuracy: 0.9145\n",
            "Epoch 86/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1881 - accuracy: 0.9134\n",
            "Epoch 87/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1852 - accuracy: 0.9137\n",
            "Epoch 88/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1832 - accuracy: 0.9147\n",
            "Epoch 89/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1813 - accuracy: 0.9156\n",
            "Epoch 90/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1821 - accuracy: 0.9147\n",
            "Epoch 91/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1811 - accuracy: 0.9161\n",
            "Epoch 92/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1811 - accuracy: 0.9161\n",
            "Epoch 93/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1797 - accuracy: 0.9157\n",
            "Epoch 94/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1786 - accuracy: 0.9177\n",
            "Epoch 95/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1774 - accuracy: 0.9168\n",
            "Epoch 96/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1807 - accuracy: 0.9157\n",
            "Epoch 97/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1763 - accuracy: 0.9190\n",
            "Epoch 98/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1766 - accuracy: 0.9190\n",
            "Epoch 99/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1757 - accuracy: 0.9178\n",
            "Epoch 100/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1730 - accuracy: 0.9207\n",
            "Epoch 101/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1775 - accuracy: 0.9180\n",
            "Epoch 102/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1740 - accuracy: 0.9193\n",
            "Epoch 103/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1727 - accuracy: 0.9211\n",
            "Epoch 104/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1716 - accuracy: 0.9199\n",
            "Epoch 105/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1713 - accuracy: 0.9200\n",
            "Epoch 106/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1708 - accuracy: 0.9199\n",
            "Epoch 107/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1708 - accuracy: 0.9217\n",
            "Epoch 108/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1692 - accuracy: 0.9223\n",
            "Epoch 109/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1683 - accuracy: 0.9217\n",
            "Epoch 110/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1684 - accuracy: 0.9219\n",
            "Epoch 111/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1670 - accuracy: 0.9228\n",
            "Epoch 112/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1670 - accuracy: 0.9232\n",
            "Epoch 113/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1680 - accuracy: 0.9215\n",
            "Epoch 114/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1666 - accuracy: 0.9236\n",
            "Epoch 115/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1662 - accuracy: 0.9225\n",
            "Epoch 116/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1650 - accuracy: 0.9242\n",
            "Epoch 117/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1658 - accuracy: 0.9232\n",
            "Epoch 118/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1644 - accuracy: 0.9234\n",
            "Epoch 119/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1637 - accuracy: 0.9240\n",
            "Epoch 120/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1626 - accuracy: 0.9242\n",
            "Epoch 121/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1615 - accuracy: 0.9256\n",
            "Epoch 122/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1626 - accuracy: 0.9251\n",
            "Epoch 123/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1602 - accuracy: 0.9255\n",
            "Epoch 124/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1606 - accuracy: 0.9258\n",
            "Epoch 125/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1627 - accuracy: 0.9271\n",
            "Epoch 126/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1599 - accuracy: 0.9258\n",
            "Epoch 127/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1593 - accuracy: 0.9271\n",
            "Epoch 128/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1568 - accuracy: 0.9282\n",
            "Epoch 129/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1588 - accuracy: 0.9269\n",
            "Epoch 130/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1565 - accuracy: 0.9281\n",
            "Epoch 131/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1569 - accuracy: 0.9278\n",
            "Epoch 132/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1565 - accuracy: 0.9276\n",
            "Epoch 133/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1592 - accuracy: 0.9259\n",
            "Epoch 134/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1570 - accuracy: 0.9281\n",
            "Epoch 135/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1575 - accuracy: 0.9274\n",
            "Epoch 136/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1554 - accuracy: 0.9288\n",
            "Epoch 137/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1549 - accuracy: 0.9281\n",
            "Epoch 138/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1552 - accuracy: 0.9286\n",
            "Epoch 139/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1541 - accuracy: 0.9276\n",
            "Epoch 140/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1543 - accuracy: 0.9287\n",
            "Epoch 141/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1526 - accuracy: 0.9296\n",
            "Epoch 142/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1519 - accuracy: 0.9292\n",
            "Epoch 143/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1558 - accuracy: 0.9281\n",
            "Epoch 144/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1513 - accuracy: 0.9314\n",
            "Epoch 145/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1512 - accuracy: 0.9311\n",
            "Epoch 146/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1501 - accuracy: 0.9313\n",
            "Epoch 147/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1499 - accuracy: 0.9308\n",
            "Epoch 148/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1491 - accuracy: 0.9324\n",
            "Epoch 149/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1508 - accuracy: 0.9305\n",
            "Epoch 150/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1511 - accuracy: 0.9306\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 150 and unit: 82\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.1369 - accuracy: 0.9390\n",
            "Train score: 0.13688597083091736\n",
            "Train accuracy: 0.9389669895172119\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 150 and unit:82\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 0.8482 - accuracy: 0.8138\n",
            "Test score: 0.8481611013412476\n",
            "Test accuracy: 0.8137992024421692\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8137992038920832\n",
            "Precision: 0.627906976744186\n",
            "Recall: 0.6103509815585961\n",
            "F1 Score: 0.6190045248868778\n",
            "Epoch 1/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3309 - accuracy: 0.8467\n",
            "Epoch 2/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3139 - accuracy: 0.8558\n",
            "Epoch 3/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3091 - accuracy: 0.8579\n",
            "Epoch 4/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3045 - accuracy: 0.8613\n",
            "Epoch 5/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3014 - accuracy: 0.8614\n",
            "Epoch 6/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2980 - accuracy: 0.8641\n",
            "Epoch 7/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2941 - accuracy: 0.8655\n",
            "Epoch 8/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2908 - accuracy: 0.8668\n",
            "Epoch 9/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2864 - accuracy: 0.8677\n",
            "Epoch 10/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2826 - accuracy: 0.8706\n",
            "Epoch 11/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2792 - accuracy: 0.8714\n",
            "Epoch 12/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2748 - accuracy: 0.8725\n",
            "Epoch 13/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2713 - accuracy: 0.8741\n",
            "Epoch 14/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2677 - accuracy: 0.8763\n",
            "Epoch 15/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2639 - accuracy: 0.8768\n",
            "Epoch 16/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2607 - accuracy: 0.8796\n",
            "Epoch 17/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2572 - accuracy: 0.8800\n",
            "Epoch 18/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2543 - accuracy: 0.8820\n",
            "Epoch 19/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2499 - accuracy: 0.8835\n",
            "Epoch 20/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2474 - accuracy: 0.8860\n",
            "Epoch 21/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2436 - accuracy: 0.8868\n",
            "Epoch 22/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2399 - accuracy: 0.8892\n",
            "Epoch 23/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2372 - accuracy: 0.8891\n",
            "Epoch 24/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2349 - accuracy: 0.8903\n",
            "Epoch 25/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2301 - accuracy: 0.8939\n",
            "Epoch 26/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2277 - accuracy: 0.8938\n",
            "Epoch 27/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2244 - accuracy: 0.8961\n",
            "Epoch 28/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2241 - accuracy: 0.8959\n",
            "Epoch 29/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2181 - accuracy: 0.8977\n",
            "Epoch 30/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2165 - accuracy: 0.8988\n",
            "Epoch 31/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2139 - accuracy: 0.9005\n",
            "Epoch 32/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2108 - accuracy: 0.9026\n",
            "Epoch 33/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2085 - accuracy: 0.9022\n",
            "Epoch 34/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2084 - accuracy: 0.9038\n",
            "Epoch 35/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2033 - accuracy: 0.9050\n",
            "Epoch 36/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2012 - accuracy: 0.9070\n",
            "Epoch 37/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1995 - accuracy: 0.9076\n",
            "Epoch 38/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1969 - accuracy: 0.9082\n",
            "Epoch 39/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1946 - accuracy: 0.9100\n",
            "Epoch 40/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1925 - accuracy: 0.9110\n",
            "Epoch 41/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1894 - accuracy: 0.9120\n",
            "Epoch 42/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1895 - accuracy: 0.9118\n",
            "Epoch 43/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1862 - accuracy: 0.9129\n",
            "Epoch 44/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1827 - accuracy: 0.9148\n",
            "Epoch 45/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1828 - accuracy: 0.9148\n",
            "Epoch 46/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1813 - accuracy: 0.9154\n",
            "Epoch 47/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1787 - accuracy: 0.9181\n",
            "Epoch 48/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1754 - accuracy: 0.9182\n",
            "Epoch 49/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1748 - accuracy: 0.9186\n",
            "Epoch 50/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1746 - accuracy: 0.9197\n",
            "Epoch 51/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1719 - accuracy: 0.9199\n",
            "Epoch 52/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1700 - accuracy: 0.9209\n",
            "Epoch 53/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1696 - accuracy: 0.9200\n",
            "Epoch 54/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1662 - accuracy: 0.9234\n",
            "Epoch 55/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1666 - accuracy: 0.9229\n",
            "Epoch 56/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1642 - accuracy: 0.9238\n",
            "Epoch 57/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1637 - accuracy: 0.9239\n",
            "Epoch 58/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1629 - accuracy: 0.9247\n",
            "Epoch 59/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1609 - accuracy: 0.9259\n",
            "Epoch 60/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1583 - accuracy: 0.9267\n",
            "Epoch 61/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1570 - accuracy: 0.9274\n",
            "Epoch 62/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1568 - accuracy: 0.9277\n",
            "Epoch 63/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1566 - accuracy: 0.9279\n",
            "Epoch 64/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1535 - accuracy: 0.9289\n",
            "Epoch 65/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1533 - accuracy: 0.9297\n",
            "Epoch 66/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1517 - accuracy: 0.9290\n",
            "Epoch 67/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1500 - accuracy: 0.9306\n",
            "Epoch 68/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1524 - accuracy: 0.9291\n",
            "Epoch 69/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1473 - accuracy: 0.9323\n",
            "Epoch 70/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1477 - accuracy: 0.9315\n",
            "Epoch 71/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1466 - accuracy: 0.9317\n",
            "Epoch 72/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1460 - accuracy: 0.9327\n",
            "Epoch 73/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1432 - accuracy: 0.9336\n",
            "Epoch 74/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1450 - accuracy: 0.9338\n",
            "Epoch 75/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1427 - accuracy: 0.9347\n",
            "Epoch 76/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1399 - accuracy: 0.9358\n",
            "Epoch 77/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1391 - accuracy: 0.9358\n",
            "Epoch 78/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1374 - accuracy: 0.9357\n",
            "Epoch 79/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1388 - accuracy: 0.9356\n",
            "Epoch 80/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1372 - accuracy: 0.9372\n",
            "Epoch 81/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1373 - accuracy: 0.9365\n",
            "Epoch 82/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1361 - accuracy: 0.9361\n",
            "Epoch 83/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1329 - accuracy: 0.9394\n",
            "Epoch 84/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1373 - accuracy: 0.9378\n",
            "Epoch 85/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1311 - accuracy: 0.9399\n",
            "Epoch 86/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1307 - accuracy: 0.9388\n",
            "Epoch 87/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1320 - accuracy: 0.9383\n",
            "Epoch 88/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1320 - accuracy: 0.9400\n",
            "Epoch 89/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1310 - accuracy: 0.9411\n",
            "Epoch 90/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1301 - accuracy: 0.9405\n",
            "Epoch 91/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1321 - accuracy: 0.9399\n",
            "Epoch 92/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1244 - accuracy: 0.9425\n",
            "Epoch 93/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1310 - accuracy: 0.9409\n",
            "Epoch 94/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1290 - accuracy: 0.9418\n",
            "Epoch 95/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1243 - accuracy: 0.9432\n",
            "Epoch 96/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1229 - accuracy: 0.9437\n",
            "Epoch 97/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1274 - accuracy: 0.9417\n",
            "Epoch 98/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1250 - accuracy: 0.9427\n",
            "Epoch 99/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1247 - accuracy: 0.9431\n",
            "Epoch 100/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1217 - accuracy: 0.9447\n",
            "Epoch 101/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1222 - accuracy: 0.9440\n",
            "Epoch 102/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1218 - accuracy: 0.9442\n",
            "Epoch 103/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1193 - accuracy: 0.9457\n",
            "Epoch 104/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1221 - accuracy: 0.9449\n",
            "Epoch 105/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1250 - accuracy: 0.9425\n",
            "Epoch 106/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1176 - accuracy: 0.9466\n",
            "Epoch 107/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1199 - accuracy: 0.9456\n",
            "Epoch 108/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1173 - accuracy: 0.9455\n",
            "Epoch 109/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1220 - accuracy: 0.9455\n",
            "Epoch 110/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1177 - accuracy: 0.9466\n",
            "Epoch 111/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1123 - accuracy: 0.9484\n",
            "Epoch 112/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1152 - accuracy: 0.9463\n",
            "Epoch 113/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1179 - accuracy: 0.9460\n",
            "Epoch 114/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1171 - accuracy: 0.9466\n",
            "Epoch 115/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1151 - accuracy: 0.9483\n",
            "Epoch 116/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1159 - accuracy: 0.9473\n",
            "Epoch 117/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1132 - accuracy: 0.9480\n",
            "Epoch 118/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1126 - accuracy: 0.9479\n",
            "Epoch 119/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1127 - accuracy: 0.9493\n",
            "Epoch 120/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1104 - accuracy: 0.9504\n",
            "Epoch 121/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1141 - accuracy: 0.9487\n",
            "Epoch 122/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1131 - accuracy: 0.9487\n",
            "Epoch 123/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1103 - accuracy: 0.9500\n",
            "Epoch 124/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1067 - accuracy: 0.9525\n",
            "Epoch 125/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1089 - accuracy: 0.9508\n",
            "Epoch 126/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1106 - accuracy: 0.9491\n",
            "Epoch 127/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1099 - accuracy: 0.9511\n",
            "Epoch 128/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1084 - accuracy: 0.9517\n",
            "Epoch 129/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1050 - accuracy: 0.9511\n",
            "Epoch 130/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1075 - accuracy: 0.9513\n",
            "Epoch 131/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1140 - accuracy: 0.9506\n",
            "Epoch 132/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1058 - accuracy: 0.9512\n",
            "Epoch 133/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1031 - accuracy: 0.9533\n",
            "Epoch 134/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1047 - accuracy: 0.9532\n",
            "Epoch 135/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1035 - accuracy: 0.9532\n",
            "Epoch 136/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1047 - accuracy: 0.9520\n",
            "Epoch 137/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1030 - accuracy: 0.9539\n",
            "Epoch 138/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1019 - accuracy: 0.9529\n",
            "Epoch 139/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1134 - accuracy: 0.9532\n",
            "Epoch 140/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1055 - accuracy: 0.9532\n",
            "Epoch 141/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1027 - accuracy: 0.9545\n",
            "Epoch 142/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1015 - accuracy: 0.9555\n",
            "Epoch 143/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1007 - accuracy: 0.9542\n",
            "Epoch 144/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0995 - accuracy: 0.9555\n",
            "Epoch 145/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1035 - accuracy: 0.9530\n",
            "Epoch 146/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0993 - accuracy: 0.9551\n",
            "Epoch 147/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1028 - accuracy: 0.9536\n",
            "Epoch 148/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0975 - accuracy: 0.9564\n",
            "Epoch 149/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1016 - accuracy: 0.9558\n",
            "Epoch 150/150\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0992 - accuracy: 0.9552\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 150 and unit: 160\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.0898 - accuracy: 0.9611\n",
            "Train score: 0.0898355171084404\n",
            "Train accuracy: 0.9610803723335266\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 150 and unit:160\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 1.5092 - accuracy: 0.8156\n",
            "Test score: 1.5092172622680664\n",
            "Test accuracy: 0.8155683279037476\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8155683325961963\n",
            "Precision: 0.6279761904761905\n",
            "Recall: 0.6276026174895896\n",
            "F1 Score: 0.627789348408212\n",
            "Epoch 1/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8421\n",
            "Epoch 2/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3164 - accuracy: 0.8538\n",
            "Epoch 3/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3130 - accuracy: 0.8557\n",
            "Epoch 4/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3104 - accuracy: 0.8567\n",
            "Epoch 5/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3088 - accuracy: 0.8568\n",
            "Epoch 6/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3072 - accuracy: 0.8579\n",
            "Epoch 7/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3054 - accuracy: 0.8589\n",
            "Epoch 8/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3037 - accuracy: 0.8605\n",
            "Epoch 9/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3026 - accuracy: 0.8596\n",
            "Epoch 10/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3007 - accuracy: 0.8617\n",
            "Epoch 11/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3002 - accuracy: 0.8608\n",
            "Epoch 12/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2988 - accuracy: 0.8625\n",
            "Epoch 13/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2974 - accuracy: 0.8624\n",
            "Epoch 14/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2959 - accuracy: 0.8633\n",
            "Epoch 15/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2947 - accuracy: 0.8643\n",
            "Epoch 16/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2933 - accuracy: 0.8650\n",
            "Epoch 17/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2923 - accuracy: 0.8645\n",
            "Epoch 18/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2908 - accuracy: 0.8658\n",
            "Epoch 19/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2897 - accuracy: 0.8662\n",
            "Epoch 20/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2886 - accuracy: 0.8673\n",
            "Epoch 21/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2870 - accuracy: 0.8670\n",
            "Epoch 22/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2861 - accuracy: 0.8680\n",
            "Epoch 23/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2854 - accuracy: 0.8689\n",
            "Epoch 24/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2843 - accuracy: 0.8691\n",
            "Epoch 25/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2832 - accuracy: 0.8687\n",
            "Epoch 26/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2821 - accuracy: 0.8700\n",
            "Epoch 27/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2816 - accuracy: 0.8710\n",
            "Epoch 28/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2804 - accuracy: 0.8703\n",
            "Epoch 29/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2794 - accuracy: 0.8716\n",
            "Epoch 30/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2788 - accuracy: 0.8716\n",
            "Epoch 31/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2775 - accuracy: 0.8730\n",
            "Epoch 32/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2768 - accuracy: 0.8726\n",
            "Epoch 33/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2762 - accuracy: 0.8719\n",
            "Epoch 34/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2753 - accuracy: 0.8726\n",
            "Epoch 35/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2740 - accuracy: 0.8724\n",
            "Epoch 36/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2736 - accuracy: 0.8740\n",
            "Epoch 37/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2726 - accuracy: 0.8735\n",
            "Epoch 38/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2717 - accuracy: 0.8737\n",
            "Epoch 39/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2710 - accuracy: 0.8750\n",
            "Epoch 40/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2700 - accuracy: 0.8762\n",
            "Epoch 41/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2699 - accuracy: 0.8756\n",
            "Epoch 42/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2686 - accuracy: 0.8768\n",
            "Epoch 43/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2683 - accuracy: 0.8758\n",
            "Epoch 44/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2671 - accuracy: 0.8770\n",
            "Epoch 45/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2663 - accuracy: 0.8770\n",
            "Epoch 46/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2659 - accuracy: 0.8776\n",
            "Epoch 47/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2656 - accuracy: 0.8779\n",
            "Epoch 48/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2644 - accuracy: 0.8776\n",
            "Epoch 49/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2642 - accuracy: 0.8789\n",
            "Epoch 50/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2632 - accuracy: 0.8787\n",
            "Epoch 51/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2623 - accuracy: 0.8791\n",
            "Epoch 52/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2617 - accuracy: 0.8786\n",
            "Epoch 53/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2615 - accuracy: 0.8788\n",
            "Epoch 54/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2610 - accuracy: 0.8792\n",
            "Epoch 55/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2595 - accuracy: 0.8797\n",
            "Epoch 56/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2592 - accuracy: 0.8790\n",
            "Epoch 57/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2584 - accuracy: 0.8795\n",
            "Epoch 58/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2582 - accuracy: 0.8811\n",
            "Epoch 59/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2577 - accuracy: 0.8820\n",
            "Epoch 60/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2566 - accuracy: 0.8821\n",
            "Epoch 61/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2560 - accuracy: 0.8814\n",
            "Epoch 62/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2552 - accuracy: 0.8832\n",
            "Epoch 63/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2554 - accuracy: 0.8817\n",
            "Epoch 64/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2553 - accuracy: 0.8821\n",
            "Epoch 65/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2543 - accuracy: 0.8830\n",
            "Epoch 66/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2537 - accuracy: 0.8837\n",
            "Epoch 67/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2534 - accuracy: 0.8835\n",
            "Epoch 68/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2526 - accuracy: 0.8825\n",
            "Epoch 69/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2525 - accuracy: 0.8836\n",
            "Epoch 70/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2516 - accuracy: 0.8847\n",
            "Epoch 71/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.8851\n",
            "Epoch 72/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2509 - accuracy: 0.8856\n",
            "Epoch 73/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2502 - accuracy: 0.8844\n",
            "Epoch 74/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2502 - accuracy: 0.8852\n",
            "Epoch 75/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2498 - accuracy: 0.8835\n",
            "Epoch 76/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2496 - accuracy: 0.8852\n",
            "Epoch 77/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2492 - accuracy: 0.8851\n",
            "Epoch 78/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2490 - accuracy: 0.8860\n",
            "Epoch 79/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2487 - accuracy: 0.8861\n",
            "Epoch 80/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2474 - accuracy: 0.8855\n",
            "Epoch 81/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2473 - accuracy: 0.8861\n",
            "Epoch 82/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2469 - accuracy: 0.8853\n",
            "Epoch 83/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2464 - accuracy: 0.8873\n",
            "Epoch 84/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2457 - accuracy: 0.8862\n",
            "Epoch 85/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2463 - accuracy: 0.8878\n",
            "Epoch 86/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2458 - accuracy: 0.8867\n",
            "Epoch 87/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2451 - accuracy: 0.8868\n",
            "Epoch 88/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2455 - accuracy: 0.8863\n",
            "Epoch 89/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
            "Epoch 90/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2449 - accuracy: 0.8881\n",
            "Epoch 91/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2440 - accuracy: 0.8881\n",
            "Epoch 92/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2436 - accuracy: 0.8873\n",
            "Epoch 93/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.8870\n",
            "Epoch 94/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2432 - accuracy: 0.8879\n",
            "Epoch 95/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2423 - accuracy: 0.8881\n",
            "Epoch 96/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2425 - accuracy: 0.8892\n",
            "Epoch 97/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2419 - accuracy: 0.8887\n",
            "Epoch 98/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2419 - accuracy: 0.8886\n",
            "Epoch 99/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2418 - accuracy: 0.8885\n",
            "Epoch 100/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2405 - accuracy: 0.8885\n",
            "Epoch 101/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2412 - accuracy: 0.8889\n",
            "Epoch 102/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2402 - accuracy: 0.8891\n",
            "Epoch 103/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2408 - accuracy: 0.8898\n",
            "Epoch 104/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2403 - accuracy: 0.8887\n",
            "Epoch 105/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2399 - accuracy: 0.8890\n",
            "Epoch 106/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2388 - accuracy: 0.8902\n",
            "Epoch 107/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2397 - accuracy: 0.8896\n",
            "Epoch 108/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2390 - accuracy: 0.8893\n",
            "Epoch 109/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2384 - accuracy: 0.8895\n",
            "Epoch 110/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2389 - accuracy: 0.8896\n",
            "Epoch 111/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2376 - accuracy: 0.8892\n",
            "Epoch 112/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2388 - accuracy: 0.8902\n",
            "Epoch 113/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2373 - accuracy: 0.8898\n",
            "Epoch 114/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2374 - accuracy: 0.8898\n",
            "Epoch 115/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2369 - accuracy: 0.8904\n",
            "Epoch 116/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2364 - accuracy: 0.8919\n",
            "Epoch 117/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2370 - accuracy: 0.8905\n",
            "Epoch 118/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2365 - accuracy: 0.8901\n",
            "Epoch 119/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2360 - accuracy: 0.8928\n",
            "Epoch 120/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2362 - accuracy: 0.8906\n",
            "Epoch 121/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2362 - accuracy: 0.8924\n",
            "Epoch 122/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2351 - accuracy: 0.8906\n",
            "Epoch 123/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2348 - accuracy: 0.8927\n",
            "Epoch 124/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2345 - accuracy: 0.8941\n",
            "Epoch 125/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2346 - accuracy: 0.8916\n",
            "Epoch 126/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2343 - accuracy: 0.8921\n",
            "Epoch 127/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2339 - accuracy: 0.8918\n",
            "Epoch 128/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2344 - accuracy: 0.8916\n",
            "Epoch 129/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2337 - accuracy: 0.8923\n",
            "Epoch 130/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2334 - accuracy: 0.8925\n",
            "Epoch 131/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2334 - accuracy: 0.8923\n",
            "Epoch 132/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2325 - accuracy: 0.8930\n",
            "Epoch 133/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2327 - accuracy: 0.8938\n",
            "Epoch 134/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2335 - accuracy: 0.8940\n",
            "Epoch 135/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2318 - accuracy: 0.8928\n",
            "Epoch 136/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2321 - accuracy: 0.8930\n",
            "Epoch 137/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2319 - accuracy: 0.8918\n",
            "Epoch 138/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2321 - accuracy: 0.8934\n",
            "Epoch 139/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2327 - accuracy: 0.8936\n",
            "Epoch 140/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2311 - accuracy: 0.8937\n",
            "Epoch 141/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2302 - accuracy: 0.8946\n",
            "Epoch 142/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2310 - accuracy: 0.8935\n",
            "Epoch 143/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2310 - accuracy: 0.8945\n",
            "Epoch 144/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2309 - accuracy: 0.8936\n",
            "Epoch 145/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2305 - accuracy: 0.8929\n",
            "Epoch 146/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2307 - accuracy: 0.8929\n",
            "Epoch 147/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2299 - accuracy: 0.8935\n",
            "Epoch 148/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2300 - accuracy: 0.8943\n",
            "Epoch 149/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2301 - accuracy: 0.8948\n",
            "Epoch 150/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2304 - accuracy: 0.8936\n",
            "Epoch 151/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2292 - accuracy: 0.8945\n",
            "Epoch 152/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2289 - accuracy: 0.8958\n",
            "Epoch 153/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2294 - accuracy: 0.8938\n",
            "Epoch 154/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2288 - accuracy: 0.8941\n",
            "Epoch 155/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2284 - accuracy: 0.8952\n",
            "Epoch 156/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2285 - accuracy: 0.8935\n",
            "Epoch 157/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2285 - accuracy: 0.8959\n",
            "Epoch 158/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2292 - accuracy: 0.8947\n",
            "Epoch 159/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2293 - accuracy: 0.8941\n",
            "Epoch 160/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2278 - accuracy: 0.8946\n",
            "Epoch 161/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2286 - accuracy: 0.8934\n",
            "Epoch 162/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2269 - accuracy: 0.8956\n",
            "Epoch 163/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2274 - accuracy: 0.8959\n",
            "Epoch 164/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2272 - accuracy: 0.8956\n",
            "Epoch 165/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2282 - accuracy: 0.8943\n",
            "Epoch 166/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2272 - accuracy: 0.8946\n",
            "Epoch 167/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2269 - accuracy: 0.8954\n",
            "Epoch 168/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2270 - accuracy: 0.8946\n",
            "Epoch 169/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2267 - accuracy: 0.8955\n",
            "Epoch 170/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2267 - accuracy: 0.8940\n",
            "Epoch 171/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2256 - accuracy: 0.8964\n",
            "Epoch 172/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2265 - accuracy: 0.8958\n",
            "Epoch 173/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2260 - accuracy: 0.8961\n",
            "Epoch 174/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2259 - accuracy: 0.8958\n",
            "Epoch 175/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2249 - accuracy: 0.8965\n",
            "Epoch 176/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2259 - accuracy: 0.8950\n",
            "Epoch 177/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2260 - accuracy: 0.8963\n",
            "Epoch 178/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2256 - accuracy: 0.8964\n",
            "Epoch 179/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2253 - accuracy: 0.8947\n",
            "Epoch 180/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2248 - accuracy: 0.8967\n",
            "Epoch 181/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2244 - accuracy: 0.8970\n",
            "Epoch 182/200\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2248 - accuracy: 0.8965\n",
            "Epoch 183/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2247 - accuracy: 0.8960\n",
            "Epoch 184/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2243 - accuracy: 0.8963\n",
            "Epoch 185/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2241 - accuracy: 0.8964\n",
            "Epoch 186/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2244 - accuracy: 0.8958\n",
            "Epoch 187/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2238 - accuracy: 0.8962\n",
            "Epoch 188/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2234 - accuracy: 0.8962\n",
            "Epoch 189/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2236 - accuracy: 0.8961\n",
            "Epoch 190/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2229 - accuracy: 0.8976\n",
            "Epoch 191/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2233 - accuracy: 0.8958\n",
            "Epoch 192/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2234 - accuracy: 0.8967\n",
            "Epoch 193/200\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2226 - accuracy: 0.8969\n",
            "Epoch 194/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2232 - accuracy: 0.8968\n",
            "Epoch 195/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2225 - accuracy: 0.8971\n",
            "Epoch 196/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2221 - accuracy: 0.8973\n",
            "Epoch 197/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2218 - accuracy: 0.8989\n",
            "Epoch 198/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2220 - accuracy: 0.8968\n",
            "Epoch 199/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2225 - accuracy: 0.8963\n",
            "Epoch 200/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2206 - accuracy: 0.8995\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 200 and unit: 40\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2160 - accuracy: 0.8998\n",
            "Train score: 0.21597369015216827\n",
            "Train accuracy: 0.8997946381568909\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 200 and unit:40\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8280\n",
            "Test score: 0.4919036328792572\n",
            "Test accuracy: 0.8279522061347961\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8279522335249889\n",
            "Precision: 0.6992248062015504\n",
            "Recall: 0.5365853658536586\n",
            "F1 Score: 0.6072029619656681\n",
            "Epoch 1/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3326 - accuracy: 0.8447\n",
            "Epoch 2/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3146 - accuracy: 0.8530\n",
            "Epoch 3/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3105 - accuracy: 0.8553\n",
            "Epoch 4/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3073 - accuracy: 0.8593\n",
            "Epoch 5/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3034 - accuracy: 0.8594\n",
            "Epoch 6/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2998 - accuracy: 0.8623\n",
            "Epoch 7/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2982 - accuracy: 0.8631\n",
            "Epoch 8/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2952 - accuracy: 0.8646\n",
            "Epoch 9/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2927 - accuracy: 0.8655\n",
            "Epoch 10/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2902 - accuracy: 0.8663\n",
            "Epoch 11/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2882 - accuracy: 0.8672\n",
            "Epoch 12/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2854 - accuracy: 0.8690\n",
            "Epoch 13/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2840 - accuracy: 0.8682\n",
            "Epoch 14/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2816 - accuracy: 0.8706\n",
            "Epoch 15/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2789 - accuracy: 0.8706\n",
            "Epoch 16/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2769 - accuracy: 0.8726\n",
            "Epoch 17/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2747 - accuracy: 0.8741\n",
            "Epoch 18/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2732 - accuracy: 0.8742\n",
            "Epoch 19/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2714 - accuracy: 0.8745\n",
            "Epoch 20/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2680 - accuracy: 0.8772\n",
            "Epoch 21/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2664 - accuracy: 0.8769\n",
            "Epoch 22/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2638 - accuracy: 0.8777\n",
            "Epoch 23/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2626 - accuracy: 0.8779\n",
            "Epoch 24/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2606 - accuracy: 0.8794\n",
            "Epoch 25/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2583 - accuracy: 0.8806\n",
            "Epoch 26/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2568 - accuracy: 0.8821\n",
            "Epoch 27/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2548 - accuracy: 0.8813\n",
            "Epoch 28/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2534 - accuracy: 0.8829\n",
            "Epoch 29/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2509 - accuracy: 0.8831\n",
            "Epoch 30/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2493 - accuracy: 0.8857\n",
            "Epoch 31/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2479 - accuracy: 0.8846\n",
            "Epoch 32/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2471 - accuracy: 0.8844\n",
            "Epoch 33/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2448 - accuracy: 0.8861\n",
            "Epoch 34/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2429 - accuracy: 0.8877\n",
            "Epoch 35/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2409 - accuracy: 0.8889\n",
            "Epoch 36/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2408 - accuracy: 0.8884\n",
            "Epoch 37/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2385 - accuracy: 0.8905\n",
            "Epoch 38/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2365 - accuracy: 0.8918\n",
            "Epoch 39/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2362 - accuracy: 0.8921\n",
            "Epoch 40/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2336 - accuracy: 0.8910\n",
            "Epoch 41/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2325 - accuracy: 0.8927\n",
            "Epoch 42/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2316 - accuracy: 0.8923\n",
            "Epoch 43/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2298 - accuracy: 0.8944\n",
            "Epoch 44/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2285 - accuracy: 0.8939\n",
            "Epoch 45/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2271 - accuracy: 0.8953\n",
            "Epoch 46/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2249 - accuracy: 0.8961\n",
            "Epoch 47/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2246 - accuracy: 0.8967\n",
            "Epoch 48/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2229 - accuracy: 0.8967\n",
            "Epoch 49/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2217 - accuracy: 0.8994\n",
            "Epoch 50/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2196 - accuracy: 0.8991\n",
            "Epoch 51/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2188 - accuracy: 0.8996\n",
            "Epoch 52/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2178 - accuracy: 0.8999\n",
            "Epoch 53/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2173 - accuracy: 0.9001\n",
            "Epoch 54/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2155 - accuracy: 0.8999\n",
            "Epoch 55/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2138 - accuracy: 0.9009\n",
            "Epoch 56/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2131 - accuracy: 0.9019\n",
            "Epoch 57/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2124 - accuracy: 0.9005\n",
            "Epoch 58/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2107 - accuracy: 0.9038\n",
            "Epoch 59/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2093 - accuracy: 0.9037\n",
            "Epoch 60/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2085 - accuracy: 0.9035\n",
            "Epoch 61/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2067 - accuracy: 0.9049\n",
            "Epoch 62/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2056 - accuracy: 0.9051\n",
            "Epoch 63/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2047 - accuracy: 0.9048\n",
            "Epoch 64/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2045 - accuracy: 0.9056\n",
            "Epoch 65/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2033 - accuracy: 0.9062\n",
            "Epoch 66/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2015 - accuracy: 0.9074\n",
            "Epoch 67/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2005 - accuracy: 0.9087\n",
            "Epoch 68/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2002 - accuracy: 0.9075\n",
            "Epoch 69/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1994 - accuracy: 0.9079\n",
            "Epoch 70/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1976 - accuracy: 0.9094\n",
            "Epoch 71/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1973 - accuracy: 0.9088\n",
            "Epoch 72/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1951 - accuracy: 0.9100\n",
            "Epoch 73/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1949 - accuracy: 0.9103\n",
            "Epoch 74/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1936 - accuracy: 0.9108\n",
            "Epoch 75/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1930 - accuracy: 0.9104\n",
            "Epoch 76/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1920 - accuracy: 0.9112\n",
            "Epoch 77/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1913 - accuracy: 0.9126\n",
            "Epoch 78/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1927 - accuracy: 0.9122\n",
            "Epoch 79/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1888 - accuracy: 0.9135\n",
            "Epoch 80/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1877 - accuracy: 0.9148\n",
            "Epoch 81/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1883 - accuracy: 0.9132\n",
            "Epoch 82/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1858 - accuracy: 0.9141\n",
            "Epoch 83/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1848 - accuracy: 0.9148\n",
            "Epoch 84/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1844 - accuracy: 0.9145\n",
            "Epoch 85/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1829 - accuracy: 0.9160\n",
            "Epoch 86/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1832 - accuracy: 0.9154\n",
            "Epoch 87/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1826 - accuracy: 0.9173\n",
            "Epoch 88/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1809 - accuracy: 0.9160\n",
            "Epoch 89/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1816 - accuracy: 0.9167\n",
            "Epoch 90/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1804 - accuracy: 0.9157\n",
            "Epoch 91/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1787 - accuracy: 0.9175\n",
            "Epoch 92/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1791 - accuracy: 0.9161\n",
            "Epoch 93/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1773 - accuracy: 0.9180\n",
            "Epoch 94/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1777 - accuracy: 0.9184\n",
            "Epoch 95/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1766 - accuracy: 0.9177\n",
            "Epoch 96/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1763 - accuracy: 0.9180\n",
            "Epoch 97/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1738 - accuracy: 0.9196\n",
            "Epoch 98/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1739 - accuracy: 0.9187\n",
            "Epoch 99/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1737 - accuracy: 0.9203\n",
            "Epoch 100/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1730 - accuracy: 0.9195\n",
            "Epoch 101/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1732 - accuracy: 0.9191\n",
            "Epoch 102/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1727 - accuracy: 0.9198\n",
            "Epoch 103/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1707 - accuracy: 0.9207\n",
            "Epoch 104/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1706 - accuracy: 0.9204\n",
            "Epoch 105/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1692 - accuracy: 0.9214\n",
            "Epoch 106/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1689 - accuracy: 0.9219\n",
            "Epoch 107/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1688 - accuracy: 0.9214\n",
            "Epoch 108/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1702 - accuracy: 0.9213\n",
            "Epoch 109/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1669 - accuracy: 0.9238\n",
            "Epoch 110/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1678 - accuracy: 0.9235\n",
            "Epoch 111/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1658 - accuracy: 0.9224\n",
            "Epoch 112/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1663 - accuracy: 0.9217\n",
            "Epoch 113/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1655 - accuracy: 0.9230\n",
            "Epoch 114/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1639 - accuracy: 0.9233\n",
            "Epoch 115/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1638 - accuracy: 0.9242\n",
            "Epoch 116/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1631 - accuracy: 0.9247\n",
            "Epoch 117/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1631 - accuracy: 0.9245\n",
            "Epoch 118/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1625 - accuracy: 0.9249\n",
            "Epoch 119/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1624 - accuracy: 0.9233\n",
            "Epoch 120/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1627 - accuracy: 0.9251\n",
            "Epoch 121/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1627 - accuracy: 0.9234\n",
            "Epoch 122/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1595 - accuracy: 0.9262\n",
            "Epoch 123/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1597 - accuracy: 0.9270\n",
            "Epoch 124/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1625 - accuracy: 0.9252\n",
            "Epoch 125/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1585 - accuracy: 0.9266\n",
            "Epoch 126/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1575 - accuracy: 0.9274\n",
            "Epoch 127/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1575 - accuracy: 0.9268\n",
            "Epoch 128/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1573 - accuracy: 0.9273\n",
            "Epoch 129/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1591 - accuracy: 0.9262\n",
            "Epoch 130/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1571 - accuracy: 0.9272\n",
            "Epoch 131/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1576 - accuracy: 0.9272\n",
            "Epoch 132/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1561 - accuracy: 0.9270\n",
            "Epoch 133/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1557 - accuracy: 0.9284\n",
            "Epoch 134/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1564 - accuracy: 0.9288\n",
            "Epoch 135/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1596 - accuracy: 0.9278\n",
            "Epoch 136/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1532 - accuracy: 0.9288\n",
            "Epoch 137/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1530 - accuracy: 0.9286\n",
            "Epoch 138/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1536 - accuracy: 0.9300\n",
            "Epoch 139/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1520 - accuracy: 0.9296\n",
            "Epoch 140/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1528 - accuracy: 0.9300\n",
            "Epoch 141/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1531 - accuracy: 0.9271\n",
            "Epoch 142/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1508 - accuracy: 0.9295\n",
            "Epoch 143/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1520 - accuracy: 0.9299\n",
            "Epoch 144/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1517 - accuracy: 0.9288\n",
            "Epoch 145/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1501 - accuracy: 0.9305\n",
            "Epoch 146/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1509 - accuracy: 0.9295\n",
            "Epoch 147/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1492 - accuracy: 0.9322\n",
            "Epoch 148/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1490 - accuracy: 0.9311\n",
            "Epoch 149/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1491 - accuracy: 0.9304\n",
            "Epoch 150/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1488 - accuracy: 0.9314\n",
            "Epoch 151/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1497 - accuracy: 0.9306\n",
            "Epoch 152/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1472 - accuracy: 0.9326\n",
            "Epoch 153/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1483 - accuracy: 0.9308\n",
            "Epoch 154/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1485 - accuracy: 0.9314\n",
            "Epoch 155/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1476 - accuracy: 0.9332\n",
            "Epoch 156/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1470 - accuracy: 0.9315\n",
            "Epoch 157/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1470 - accuracy: 0.9326\n",
            "Epoch 158/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1460 - accuracy: 0.9312\n",
            "Epoch 159/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1458 - accuracy: 0.9322\n",
            "Epoch 160/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1481 - accuracy: 0.9323\n",
            "Epoch 161/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1452 - accuracy: 0.9331\n",
            "Epoch 162/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1437 - accuracy: 0.9326\n",
            "Epoch 163/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1437 - accuracy: 0.9334\n",
            "Epoch 164/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1441 - accuracy: 0.9329\n",
            "Epoch 165/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1426 - accuracy: 0.9346\n",
            "Epoch 166/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1432 - accuracy: 0.9347\n",
            "Epoch 167/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1438 - accuracy: 0.9344\n",
            "Epoch 168/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1423 - accuracy: 0.9342\n",
            "Epoch 169/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1433 - accuracy: 0.9335\n",
            "Epoch 170/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1429 - accuracy: 0.9342\n",
            "Epoch 171/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1421 - accuracy: 0.9345\n",
            "Epoch 172/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1412 - accuracy: 0.9341\n",
            "Epoch 173/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1430 - accuracy: 0.9341\n",
            "Epoch 174/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1405 - accuracy: 0.9335\n",
            "Epoch 175/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1393 - accuracy: 0.9348\n",
            "Epoch 176/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1400 - accuracy: 0.9352\n",
            "Epoch 177/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1409 - accuracy: 0.9352\n",
            "Epoch 178/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1421 - accuracy: 0.9340\n",
            "Epoch 179/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1383 - accuracy: 0.9360\n",
            "Epoch 180/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1380 - accuracy: 0.9350\n",
            "Epoch 181/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1387 - accuracy: 0.9352\n",
            "Epoch 182/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1406 - accuracy: 0.9351\n",
            "Epoch 183/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1380 - accuracy: 0.9359\n",
            "Epoch 184/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1382 - accuracy: 0.9366\n",
            "Epoch 185/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1383 - accuracy: 0.9362\n",
            "Epoch 186/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1376 - accuracy: 0.9367\n",
            "Epoch 187/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1361 - accuracy: 0.9367\n",
            "Epoch 188/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1371 - accuracy: 0.9359\n",
            "Epoch 189/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1366 - accuracy: 0.9366\n",
            "Epoch 190/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1371 - accuracy: 0.9379\n",
            "Epoch 191/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1356 - accuracy: 0.9375\n",
            "Epoch 192/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1341 - accuracy: 0.9380\n",
            "Epoch 193/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1353 - accuracy: 0.9370\n",
            "Epoch 194/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1349 - accuracy: 0.9373\n",
            "Epoch 195/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1352 - accuracy: 0.9367\n",
            "Epoch 196/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1334 - accuracy: 0.9391\n",
            "Epoch 197/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1359 - accuracy: 0.9358\n",
            "Epoch 198/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1358 - accuracy: 0.9368\n",
            "Epoch 199/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1334 - accuracy: 0.9384\n",
            "Epoch 200/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1338 - accuracy: 0.9379\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 200 and unit: 82\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.1314 - accuracy: 0.9393\n",
            "Train score: 0.13138076663017273\n",
            "Train accuracy: 0.9393144845962524\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 200 and unit:82\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 1.0831 - accuracy: 0.8067\n",
            "Test score: 1.083086609840393\n",
            "Test accuracy: 0.8067227005958557\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8067226890756303\n",
            "Precision: 0.602436323366556\n",
            "Recall: 0.6472337894110648\n",
            "F1 Score: 0.6240321193002581\n",
            "Epoch 1/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3292 - accuracy: 0.8472\n",
            "Epoch 2/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3140 - accuracy: 0.8545\n",
            "Epoch 3/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3087 - accuracy: 0.8588\n",
            "Epoch 4/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3053 - accuracy: 0.8599\n",
            "Epoch 5/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3018 - accuracy: 0.8612\n",
            "Epoch 6/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2980 - accuracy: 0.8633\n",
            "Epoch 7/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2939 - accuracy: 0.8661\n",
            "Epoch 8/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2906 - accuracy: 0.8654\n",
            "Epoch 9/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2866 - accuracy: 0.8683\n",
            "Epoch 10/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2823 - accuracy: 0.8707\n",
            "Epoch 11/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2794 - accuracy: 0.8708\n",
            "Epoch 12/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2749 - accuracy: 0.8730\n",
            "Epoch 13/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2721 - accuracy: 0.8745\n",
            "Epoch 14/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2677 - accuracy: 0.8767\n",
            "Epoch 15/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2646 - accuracy: 0.8783\n",
            "Epoch 16/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2619 - accuracy: 0.8800\n",
            "Epoch 17/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2566 - accuracy: 0.8802\n",
            "Epoch 18/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2549 - accuracy: 0.8826\n",
            "Epoch 19/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2500 - accuracy: 0.8850\n",
            "Epoch 20/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2470 - accuracy: 0.8841\n",
            "Epoch 21/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2437 - accuracy: 0.8870\n",
            "Epoch 22/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2406 - accuracy: 0.8878\n",
            "Epoch 23/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2371 - accuracy: 0.8897\n",
            "Epoch 24/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2334 - accuracy: 0.8934\n",
            "Epoch 25/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2306 - accuracy: 0.8921\n",
            "Epoch 26/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2265 - accuracy: 0.8946\n",
            "Epoch 27/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2238 - accuracy: 0.8956\n",
            "Epoch 28/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2213 - accuracy: 0.8966\n",
            "Epoch 29/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2189 - accuracy: 0.8997\n",
            "Epoch 30/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2145 - accuracy: 0.8999\n",
            "Epoch 31/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2158 - accuracy: 0.9018\n",
            "Epoch 32/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2079 - accuracy: 0.9022\n",
            "Epoch 33/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2072 - accuracy: 0.9041\n",
            "Epoch 34/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2030 - accuracy: 0.9057\n",
            "Epoch 35/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2018 - accuracy: 0.9067\n",
            "Epoch 36/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1986 - accuracy: 0.9080\n",
            "Epoch 37/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1976 - accuracy: 0.9087\n",
            "Epoch 38/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1942 - accuracy: 0.9106\n",
            "Epoch 39/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1917 - accuracy: 0.9106\n",
            "Epoch 40/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1914 - accuracy: 0.9119\n",
            "Epoch 41/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1877 - accuracy: 0.9131\n",
            "Epoch 42/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1853 - accuracy: 0.9142\n",
            "Epoch 43/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1834 - accuracy: 0.9148\n",
            "Epoch 44/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1846 - accuracy: 0.9163\n",
            "Epoch 45/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1795 - accuracy: 0.9168\n",
            "Epoch 46/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1770 - accuracy: 0.9181\n",
            "Epoch 47/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1755 - accuracy: 0.9183\n",
            "Epoch 48/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1738 - accuracy: 0.9191\n",
            "Epoch 49/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1725 - accuracy: 0.9187\n",
            "Epoch 50/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1703 - accuracy: 0.9218\n",
            "Epoch 51/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1675 - accuracy: 0.9231\n",
            "Epoch 52/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1666 - accuracy: 0.9235\n",
            "Epoch 53/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1646 - accuracy: 0.9242\n",
            "Epoch 54/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1637 - accuracy: 0.9244\n",
            "Epoch 55/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1598 - accuracy: 0.9266\n",
            "Epoch 56/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1605 - accuracy: 0.9256\n",
            "Epoch 57/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1585 - accuracy: 0.9280\n",
            "Epoch 58/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1581 - accuracy: 0.9266\n",
            "Epoch 59/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1546 - accuracy: 0.9292\n",
            "Epoch 60/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1533 - accuracy: 0.9288\n",
            "Epoch 61/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1522 - accuracy: 0.9285\n",
            "Epoch 62/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1508 - accuracy: 0.9299\n",
            "Epoch 63/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1487 - accuracy: 0.9316\n",
            "Epoch 64/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1516 - accuracy: 0.9310\n",
            "Epoch 65/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1478 - accuracy: 0.9320\n",
            "Epoch 66/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1433 - accuracy: 0.9344\n",
            "Epoch 67/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1444 - accuracy: 0.9345\n",
            "Epoch 68/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1427 - accuracy: 0.9346\n",
            "Epoch 69/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1416 - accuracy: 0.9350\n",
            "Epoch 70/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1426 - accuracy: 0.9350\n",
            "Epoch 71/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1392 - accuracy: 0.9362\n",
            "Epoch 72/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1399 - accuracy: 0.9366\n",
            "Epoch 73/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1375 - accuracy: 0.9365\n",
            "Epoch 74/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1359 - accuracy: 0.9378\n",
            "Epoch 75/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1353 - accuracy: 0.9380\n",
            "Epoch 76/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1352 - accuracy: 0.9392\n",
            "Epoch 77/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1347 - accuracy: 0.9370\n",
            "Epoch 78/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1312 - accuracy: 0.9409\n",
            "Epoch 79/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1310 - accuracy: 0.9409\n",
            "Epoch 80/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1299 - accuracy: 0.9408\n",
            "Epoch 81/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1306 - accuracy: 0.9406\n",
            "Epoch 82/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1307 - accuracy: 0.9416\n",
            "Epoch 83/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1273 - accuracy: 0.9413\n",
            "Epoch 84/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1263 - accuracy: 0.9415\n",
            "Epoch 85/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1252 - accuracy: 0.9430\n",
            "Epoch 86/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1231 - accuracy: 0.9445\n",
            "Epoch 87/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1254 - accuracy: 0.9427\n",
            "Epoch 88/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1231 - accuracy: 0.9440\n",
            "Epoch 89/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1226 - accuracy: 0.9449\n",
            "Epoch 90/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1205 - accuracy: 0.9448\n",
            "Epoch 91/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1195 - accuracy: 0.9438\n",
            "Epoch 92/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1189 - accuracy: 0.9475\n",
            "Epoch 93/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1197 - accuracy: 0.9451\n",
            "Epoch 94/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1201 - accuracy: 0.9462\n",
            "Epoch 95/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1194 - accuracy: 0.9460\n",
            "Epoch 96/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1161 - accuracy: 0.9477\n",
            "Epoch 97/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1153 - accuracy: 0.9484\n",
            "Epoch 98/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1160 - accuracy: 0.9479\n",
            "Epoch 99/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1149 - accuracy: 0.9482\n",
            "Epoch 100/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1144 - accuracy: 0.9483\n",
            "Epoch 101/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1124 - accuracy: 0.9491\n",
            "Epoch 102/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1107 - accuracy: 0.9491\n",
            "Epoch 103/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1130 - accuracy: 0.9485\n",
            "Epoch 104/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1123 - accuracy: 0.9511\n",
            "Epoch 105/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1156 - accuracy: 0.9498\n",
            "Epoch 106/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1096 - accuracy: 0.9513\n",
            "Epoch 107/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1084 - accuracy: 0.9517\n",
            "Epoch 108/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1081 - accuracy: 0.9504\n",
            "Epoch 109/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1087 - accuracy: 0.9500\n",
            "Epoch 110/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1110 - accuracy: 0.9502\n",
            "Epoch 111/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1103 - accuracy: 0.9511\n",
            "Epoch 112/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1067 - accuracy: 0.9530\n",
            "Epoch 113/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1075 - accuracy: 0.9522\n",
            "Epoch 114/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1034 - accuracy: 0.9528\n",
            "Epoch 115/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1048 - accuracy: 0.9537\n",
            "Epoch 116/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1052 - accuracy: 0.9527\n",
            "Epoch 117/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1076 - accuracy: 0.9544\n",
            "Epoch 118/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1023 - accuracy: 0.9538\n",
            "Epoch 119/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1007 - accuracy: 0.9536\n",
            "Epoch 120/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1039 - accuracy: 0.9541\n",
            "Epoch 121/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1025 - accuracy: 0.9546\n",
            "Epoch 122/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0994 - accuracy: 0.9556\n",
            "Epoch 123/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1016 - accuracy: 0.9553\n",
            "Epoch 124/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1015 - accuracy: 0.9550\n",
            "Epoch 125/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1027 - accuracy: 0.9538\n",
            "Epoch 126/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0996 - accuracy: 0.9559\n",
            "Epoch 127/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0988 - accuracy: 0.9558\n",
            "Epoch 128/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0983 - accuracy: 0.9554\n",
            "Epoch 129/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0995 - accuracy: 0.9555\n",
            "Epoch 130/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0979 - accuracy: 0.9560\n",
            "Epoch 131/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0949 - accuracy: 0.9574\n",
            "Epoch 132/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0951 - accuracy: 0.9575\n",
            "Epoch 133/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0981 - accuracy: 0.9569\n",
            "Epoch 134/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0940 - accuracy: 0.9587\n",
            "Epoch 135/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0998 - accuracy: 0.9546\n",
            "Epoch 136/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0962 - accuracy: 0.9584\n",
            "Epoch 137/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0921 - accuracy: 0.9583\n",
            "Epoch 138/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0918 - accuracy: 0.9586\n",
            "Epoch 139/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0947 - accuracy: 0.9584\n",
            "Epoch 140/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0935 - accuracy: 0.9577\n",
            "Epoch 141/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0928 - accuracy: 0.9597\n",
            "Epoch 142/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0924 - accuracy: 0.9586\n",
            "Epoch 143/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0912 - accuracy: 0.9592\n",
            "Epoch 144/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0932 - accuracy: 0.9583\n",
            "Epoch 145/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0932 - accuracy: 0.9576\n",
            "Epoch 146/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0901 - accuracy: 0.9597\n",
            "Epoch 147/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0920 - accuracy: 0.9598\n",
            "Epoch 148/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0879 - accuracy: 0.9610\n",
            "Epoch 149/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0912 - accuracy: 0.9590\n",
            "Epoch 150/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0910 - accuracy: 0.9609\n",
            "Epoch 151/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0919 - accuracy: 0.9591\n",
            "Epoch 152/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0906 - accuracy: 0.9611\n",
            "Epoch 153/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.9615\n",
            "Epoch 154/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0891 - accuracy: 0.9593\n",
            "Epoch 155/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0882 - accuracy: 0.9607\n",
            "Epoch 156/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0875 - accuracy: 0.9595\n",
            "Epoch 157/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.9627\n",
            "Epoch 158/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0904 - accuracy: 0.9598\n",
            "Epoch 159/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0943 - accuracy: 0.9600\n",
            "Epoch 160/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0890 - accuracy: 0.9605\n",
            "Epoch 161/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.9622\n",
            "Epoch 162/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.9629\n",
            "Epoch 163/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0869 - accuracy: 0.9619\n",
            "Epoch 164/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0893 - accuracy: 0.9620\n",
            "Epoch 165/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.9621\n",
            "Epoch 166/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.9627\n",
            "Epoch 167/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0852 - accuracy: 0.9616\n",
            "Epoch 168/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.9632\n",
            "Epoch 169/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0900 - accuracy: 0.9598\n",
            "Epoch 170/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0810 - accuracy: 0.9642\n",
            "Epoch 171/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0795 - accuracy: 0.9643\n",
            "Epoch 172/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.9620\n",
            "Epoch 173/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0906 - accuracy: 0.9612\n",
            "Epoch 174/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0805 - accuracy: 0.9637\n",
            "Epoch 175/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.9626\n",
            "Epoch 176/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.9657\n",
            "Epoch 177/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0805 - accuracy: 0.9643\n",
            "Epoch 178/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.9645\n",
            "Epoch 179/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.9641\n",
            "Epoch 180/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.9637\n",
            "Epoch 181/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.9650\n",
            "Epoch 182/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.9645\n",
            "Epoch 183/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.9631\n",
            "Epoch 184/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.9659\n",
            "Epoch 185/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0814 - accuracy: 0.9645\n",
            "Epoch 186/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0769 - accuracy: 0.9665\n",
            "Epoch 187/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.9649\n",
            "Epoch 188/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.9657\n",
            "Epoch 189/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.9658\n",
            "Epoch 190/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0755 - accuracy: 0.9663\n",
            "Epoch 191/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.9658\n",
            "Epoch 192/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0766 - accuracy: 0.9654\n",
            "Epoch 193/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0817 - accuracy: 0.9663\n",
            "Epoch 194/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.9663\n",
            "Epoch 195/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0741 - accuracy: 0.9675\n",
            "Epoch 196/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0746 - accuracy: 0.9664\n",
            "Epoch 197/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0770 - accuracy: 0.9662\n",
            "Epoch 198/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0755 - accuracy: 0.9675\n",
            "Epoch 199/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.9648\n",
            "Epoch 200/200\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0765 - accuracy: 0.9660\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 200 and unit: 160\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.0625 - accuracy: 0.9735\n",
            "Train score: 0.06247052550315857\n",
            "Train accuracy: 0.9734638929367065\n",
            "********************\n",
            "\n",
            "\n",
            "Validation Score and Accuracy at epoch: 200 and unit:160\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 2.0065 - accuracy: 0.8176\n",
            "Test score: 2.0065431594848633\n",
            "Test accuracy: 0.8176323175430298\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8176323160843285\n",
            "Precision: 0.6399747793190416\n",
            "Recall: 0.6038072575847709\n",
            "F1 Score: 0.6213651668197123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CttpZKbaqvH",
        "colab_type": "text"
      },
      "source": [
        "**The best perfomance on the validation set occur at  epoch:100 , unit = 40 **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIBCCilgbCUH",
        "colab_type": "text"
      },
      "source": [
        "**Finalize the ANN Model on the Test Set**\n",
        "\n",
        "Use Epoch : 100 and unit:40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_NOGRXtw1M8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "375e55ef-761c-4278-999b-e7e0832fe18f"
      },
      "source": [
        "ann = tf.keras.Sequential() #intialize the ANN\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=40, activation='relu')) # add the input and the first hidden layer\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=40, activation='relu')) # add second hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))  #add the final output later\n",
        "ann.compile(optimizer='adam' , loss= 'binary_crossentropy', metrics=['accuracy'])      #compile the NN\n",
        "ann.fit(X_train1,y_train, batch_size= 32 , epochs=100)\n",
        "\n",
        "print('*'*20)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(f\"Training Score and Accuracy at epoch: {epoch} and unit: {unit}\")\n",
        "score, acc = ann.evaluate(X_train1, y_train, batch_size=32)\n",
        "print('Train score:', score)\n",
        "print('Train accuracy:', acc)\n",
        "\n",
        "# Predicting the Validation set results\n",
        "y_pred = ann.predict(X_test1)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "print('*'*20)\n",
        "\n",
        "print(\"\\n\")\n",
        "score, acc = ann.evaluate(X_test1, y_test, batch_size=32)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)\n",
        "        \n",
        "\n",
        "print(\"\\n\")\n",
        "print (\"Model Evaluation Metrics\")\n",
        "generate_model_report(y_test, y_pred)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3420 - accuracy: 0.8396\n",
            "Epoch 2/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3155 - accuracy: 0.8532\n",
            "Epoch 3/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3119 - accuracy: 0.8567\n",
            "Epoch 4/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3090 - accuracy: 0.8567\n",
            "Epoch 5/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3072 - accuracy: 0.8569\n",
            "Epoch 6/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3053 - accuracy: 0.8602\n",
            "Epoch 7/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3032 - accuracy: 0.8595\n",
            "Epoch 8/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.3018 - accuracy: 0.8607\n",
            "Epoch 9/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2998 - accuracy: 0.8610\n",
            "Epoch 10/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2990 - accuracy: 0.8621\n",
            "Epoch 11/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2976 - accuracy: 0.8634\n",
            "Epoch 12/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2961 - accuracy: 0.8647\n",
            "Epoch 13/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2950 - accuracy: 0.8646\n",
            "Epoch 14/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2932 - accuracy: 0.8659\n",
            "Epoch 15/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2921 - accuracy: 0.8662\n",
            "Epoch 16/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2914 - accuracy: 0.8650\n",
            "Epoch 17/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2900 - accuracy: 0.8662\n",
            "Epoch 18/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2887 - accuracy: 0.8674\n",
            "Epoch 19/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2875 - accuracy: 0.8671\n",
            "Epoch 20/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2863 - accuracy: 0.8677\n",
            "Epoch 21/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2853 - accuracy: 0.8679\n",
            "Epoch 22/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2843 - accuracy: 0.8686\n",
            "Epoch 23/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2833 - accuracy: 0.8686\n",
            "Epoch 24/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2823 - accuracy: 0.8699\n",
            "Epoch 25/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2814 - accuracy: 0.8704\n",
            "Epoch 26/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.8693\n",
            "Epoch 27/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2791 - accuracy: 0.8720\n",
            "Epoch 28/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2782 - accuracy: 0.8712\n",
            "Epoch 29/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2772 - accuracy: 0.8738\n",
            "Epoch 30/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.8721\n",
            "Epoch 31/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2750 - accuracy: 0.8734\n",
            "Epoch 32/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2743 - accuracy: 0.8735\n",
            "Epoch 33/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2735 - accuracy: 0.8742\n",
            "Epoch 34/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2725 - accuracy: 0.8747\n",
            "Epoch 35/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2723 - accuracy: 0.8750\n",
            "Epoch 36/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2712 - accuracy: 0.8763\n",
            "Epoch 37/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2706 - accuracy: 0.8757\n",
            "Epoch 38/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2701 - accuracy: 0.8739\n",
            "Epoch 39/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2695 - accuracy: 0.8755\n",
            "Epoch 40/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2684 - accuracy: 0.8778\n",
            "Epoch 41/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2674 - accuracy: 0.8776\n",
            "Epoch 42/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2670 - accuracy: 0.8782\n",
            "Epoch 43/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2666 - accuracy: 0.8776\n",
            "Epoch 44/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2654 - accuracy: 0.8776\n",
            "Epoch 45/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2654 - accuracy: 0.8790\n",
            "Epoch 46/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2649 - accuracy: 0.8780\n",
            "Epoch 47/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2637 - accuracy: 0.8774\n",
            "Epoch 48/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2632 - accuracy: 0.8789\n",
            "Epoch 49/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2624 - accuracy: 0.8804\n",
            "Epoch 50/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2625 - accuracy: 0.8795\n",
            "Epoch 51/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2614 - accuracy: 0.8814\n",
            "Epoch 52/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2608 - accuracy: 0.8800\n",
            "Epoch 53/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2604 - accuracy: 0.8811\n",
            "Epoch 54/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2597 - accuracy: 0.8809\n",
            "Epoch 55/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2586 - accuracy: 0.8820\n",
            "Epoch 56/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2583 - accuracy: 0.8814\n",
            "Epoch 57/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2578 - accuracy: 0.8817\n",
            "Epoch 58/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2573 - accuracy: 0.8818\n",
            "Epoch 59/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2560 - accuracy: 0.8826\n",
            "Epoch 60/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.8826\n",
            "Epoch 61/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2558 - accuracy: 0.8825\n",
            "Epoch 62/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2546 - accuracy: 0.8830\n",
            "Epoch 63/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2543 - accuracy: 0.8831\n",
            "Epoch 64/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2539 - accuracy: 0.8833\n",
            "Epoch 65/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2530 - accuracy: 0.8837\n",
            "Epoch 66/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2523 - accuracy: 0.8845\n",
            "Epoch 67/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2525 - accuracy: 0.8845\n",
            "Epoch 68/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2518 - accuracy: 0.8842\n",
            "Epoch 69/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2510 - accuracy: 0.8841\n",
            "Epoch 70/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2511 - accuracy: 0.8854\n",
            "Epoch 71/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2501 - accuracy: 0.8846\n",
            "Epoch 72/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2499 - accuracy: 0.8846\n",
            "Epoch 73/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2498 - accuracy: 0.8846\n",
            "Epoch 74/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2489 - accuracy: 0.8861\n",
            "Epoch 75/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2487 - accuracy: 0.8858\n",
            "Epoch 76/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2475 - accuracy: 0.8837\n",
            "Epoch 77/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2478 - accuracy: 0.8849\n",
            "Epoch 78/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2471 - accuracy: 0.8862\n",
            "Epoch 79/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2468 - accuracy: 0.8858\n",
            "Epoch 80/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2464 - accuracy: 0.8858\n",
            "Epoch 81/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2459 - accuracy: 0.8862\n",
            "Epoch 82/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2452 - accuracy: 0.8859\n",
            "Epoch 83/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2450 - accuracy: 0.8870\n",
            "Epoch 84/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2443 - accuracy: 0.8879\n",
            "Epoch 85/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2448 - accuracy: 0.8879\n",
            "Epoch 86/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2442 - accuracy: 0.8875\n",
            "Epoch 87/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2431 - accuracy: 0.8865\n",
            "Epoch 88/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2432 - accuracy: 0.8871\n",
            "Epoch 89/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2426 - accuracy: 0.8878\n",
            "Epoch 90/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2421 - accuracy: 0.8885\n",
            "Epoch 91/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2413 - accuracy: 0.8873\n",
            "Epoch 92/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2414 - accuracy: 0.8873\n",
            "Epoch 93/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2415 - accuracy: 0.8888\n",
            "Epoch 94/100\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2403 - accuracy: 0.8896\n",
            "Epoch 95/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2406 - accuracy: 0.8872\n",
            "Epoch 96/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2402 - accuracy: 0.8897\n",
            "Epoch 97/100\n",
            "990/990 [==============================] - 1s 2ms/step - loss: 0.2392 - accuracy: 0.8891\n",
            "Epoch 98/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2395 - accuracy: 0.8901\n",
            "Epoch 99/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2390 - accuracy: 0.8898\n",
            "Epoch 100/100\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2388 - accuracy: 0.8890\n",
            "********************\n",
            "\n",
            "\n",
            "Training Score and Accuracy at epoch: 200 and unit: 160\n",
            "990/990 [==============================] - 1s 1ms/step - loss: 0.2319 - accuracy: 0.8936\n",
            "Train score: 0.23188672959804535\n",
            "Train accuracy: 0.8936344981193542\n",
            "********************\n",
            "\n",
            "\n",
            "212/212 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8314\n",
            "Test score: 0.43431591987609863\n",
            "Test accuracy: 0.8313679099082947\n",
            "\n",
            "\n",
            "Model Evaluation Metrics\n",
            "Accuracy: 0.8313679245283019\n",
            "Precision: 0.6749185667752443\n",
            "Recall: 0.6162998215348007\n",
            "F1 Score: 0.6442786069651741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9B_e3Xhb9u5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5c8edb76-9379-4a99-c68a-79693dd45862"
      },
      "source": [
        "print(\"Generate Confusion Matrix\")\n",
        "\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generate Confusion Matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4604,  499],\n",
              "       [ 645, 1036]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}